{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA over unstructured data\n",
    "\n",
    "Using Match LSTM, Pointer Networks, as mentioned in paper https://arxiv.org/pdf/1608.07905.pdf\n",
    "\n",
    "We start with the pre-processing provided by https://github.com/MurtyShikhar/Question-Answering to clean up the data and make neat para, ques files.\n",
    "\n",
    "\n",
    "### @TODOs:\n",
    "\n",
    "1. [done] _Figure out how to put in real, pre-trained embeddings in embeddings layer._\n",
    "2. [done] _Explicitly provide batch size when instantiating model_\n",
    "3. [done] is ./val.ids.* validation set or test set?: **validation**\n",
    "4. [done:em] emInstead of test loss, calculate test acc metrics\n",
    "    1. todo: new metrics like P, R, F1\n",
    "5. [done] Update unit test codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import matplotlib.pyplot as plt\n",
    "from io import open\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import traceback\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from networks import Encoder, MatchLSTMEncoder, PointerDecoder\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug Legend\n",
    "\n",
    "- 5: Print everything that goes in every tensor.\n",
    "- 4: ??\n",
    "- 3: Check every model individually\n",
    "- 2: Print things in training loops\n",
    "- 1: ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macros \n",
    "DATA_LOC = './data/domain/'\n",
    "MODEL_LOC = './models/mlstms/domain/'\n",
    "DEBUG = 1\n",
    "\n",
    "# nn Macros\n",
    "QUES_LEN, PARA_LEN =  30, 200\n",
    "VOCAB_SIZE = 120000\n",
    "# VOCAB_SIZE = glove_file.shape[1]               # @TODO: get actual size\n",
    "HIDDEN_DIM = 150\n",
    "EMBEDDING_DIM = 300\n",
    "BATCH_SIZE = 50                  # Might have total 100 batches.\n",
    "EPOCHS = 300\n",
    "TEST_EVERY_ = 1\n",
    "LR = 0.001\n",
    "CROP = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder \n",
    "Use a simple lstm class to have encoder for question and paragraph. \n",
    "The output of these will be used in the match lstm\n",
    "\n",
    "$H^p = LSTM(P)$ \n",
    "\n",
    "\n",
    "$H^q = LSTM(Q)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputlen, macros, glove_file, device):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # Catch dim\n",
    "        self.inputlen = inputlen\n",
    "        self.hiddendim = macros['hidden_dim']\n",
    "        self.embeddingdim =  macros['embedding_dim']\n",
    "        self.vocablen = macros['vocab_size']\n",
    "#         self.device = macros['device']\n",
    "        self.batch_size = macros['batch_size']\n",
    "        self.debug = macros['debug']\n",
    "        \n",
    "        # Embedding Layer\n",
    "#         self.embedding = nn.Embedding(self.vocablen, self.embeddingdim)\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(glove_file))\n",
    "        self.embedding.weight.requires_grad = True\n",
    "       \n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(self.embeddingdim, self.hiddendim, bidirectional=True, batch_first=False)\n",
    "        \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        \n",
    "        # Returns a new hidden layer var for LSTM\n",
    "        return (torch.zeros((2, batch_size, self.hiddendim), device=device), \n",
    "                torch.zeros((2, batch_size, self.hiddendim), device=device))\n",
    "    \n",
    "    def forward(self, x, h, device):\n",
    "        \n",
    "        # Input: x (batch, len ) (current input)\n",
    "        # Hidden: h (1, batch, hiddendim) (last hidden state)\n",
    "        \n",
    "        # Batchsize: b int (inferred)\n",
    "        b = x.shape[0]\n",
    "        \n",
    "        if self.debug > 4: print(\"x:\\t\", x.shape)\n",
    "        if self.debug > 4: print(\"h:\\t\", h[0].shape, h[1].shape)\n",
    "        \n",
    "        x_emb = self.embedding(x)\n",
    "        if self.debug > 4: \n",
    "            print(\"x_emb:\\t\", x_emb.shape)\n",
    "#             print(\"x_emb_wrong:\\t\", x_emb.transpose(1,0).shape)           \n",
    "            \n",
    "        ycap, h = self.lstm(x_emb.transpose(1,0), h)\n",
    "        if self.debug > 4: \n",
    "            print(\"ycap:\\t\", ycap.shape)\n",
    "        \n",
    "        return ycap, h\n",
    "    \n",
    "    \n",
    "# # with torch.no_grad():\n",
    "# #     print (\"Trying out question encoder LSTM\")\n",
    "# #     model = Encoder(QUES_LEN, HIDDEN_DIM, EMBEDDING_DIM, VOCAB_SIZE)\n",
    "# #     dummy_x = torch.tensor([22,45,12], dtype=torch.long)\n",
    "# #     hidden = model.init_hidden()\n",
    "# #     ycap, h = model(dummy_x, hidden)\n",
    "    \n",
    "# #     print(ycap.shape)\n",
    "# #     print(h[0].shape, h[1].shape)\n",
    "\n",
    "\n",
    "if DEBUG > 4:\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        macros = {\n",
    "        \"ques_len\": QUES_LEN,\n",
    "        \"hidden_dim\": HIDDEN_DIM, \n",
    "        \"vocab_size\": VOCAB_SIZE, \n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"para_len\": PARA_LEN,\n",
    "        \"embedding_dim\": EMBEDDING_DIM,\n",
    "        \"lr\": LR,\n",
    "        \"debug\":5,\n",
    "        \"device\":device\n",
    "    }\n",
    "\n",
    "        dummy_para = torch.randint(0,VOCAB_SIZE-1,(PARA_LEN*BATCH_SIZE,), device=device).view(BATCH_SIZE,PARA_LEN).long()\n",
    "    #     print (dummy_para.shape)\n",
    "        dummy_question = torch.randint(0,VOCAB_SIZE-1,(QUES_LEN*BATCH_SIZE,), device=device).view(BATCH_SIZE,QUES_LEN).long()\n",
    "    #     print (dummy_question.shape)\n",
    "        glove_file = torch.randn((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "\n",
    "    #     print(\"LSTM with batches\")\n",
    "        ques_model = Encoder(QUES_LEN, macros, glove_file, device).cuda(device)\n",
    "        para_model = Encoder(QUES_LEN, macros, glove_file, device).cuda(device)\n",
    "        ques_hidden = ques_model.init_hidden(BATCH_SIZE, device)\n",
    "        para_hidden = para_model.init_hidden(BATCH_SIZE, device)\n",
    "        ques_embedded,hidden_ques = ques_model(dummy_question,ques_hidden, device)\n",
    "        para_embedded,hidden_para = para_model(dummy_para,para_hidden, device)\n",
    "        \n",
    "#         print (ques_embedded.shape) # question_length,batch,embedding_dim\n",
    "#         print (para_embedded.shape) # para_length,batch,embedding_dim\n",
    "#         print (hidden_para[0].shape,hidden_para[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match LSTM\n",
    "\n",
    "Use a match LSTM to compute a **summarized sequential vector** for the paragraph w.r.t the question.\n",
    "\n",
    "Consider the summarized vector ($H^r$) as the output of a new decoder, where the inputs are $H^p, H^q$ computed above. \n",
    "\n",
    "1. Attend the para word $i$ with the entire question ($H^q$)\n",
    "  \n",
    "    1. $\\vec{G}_i = tanh(W^qH^q + repeat(W^ph^p_i + W^r\\vec{h^r_{i-1} + b^p}))$\n",
    "    \n",
    "    2. *Computing it*: Here, $\\vec{G}_i$ is equivalent to `energy`, computed differently.\n",
    "    \n",
    "    3. Use a linear layer to compute the content within the $repeat$ fn.\n",
    "    \n",
    "    4. Add with another linear (without bias) with $H_q$\n",
    "    \n",
    "    5. $tanh$ the bloody thing\n",
    "  \n",
    "  \n",
    "2. Softmax over it to get $\\alpha$ weights.\n",
    "\n",
    "    1. $\\vec{\\alpha_i} = softmax(w^t\\vec{G}_i + repeat(b))$\n",
    "    \n",
    "3. Use the attention weight vector $\\vec{\\alpha_i}$ to obtain a weighted version of the question and concat it with the current token of the passage to form a vector $\\vec{z_i}$\n",
    "\n",
    "4. Use $\\vec{z_i}$ to compute the desired $h^r_i$:\n",
    "\n",
    "    1. $ h^r_i = LSTM(\\vec{z_i}, h^r_{i-1}) $\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchLSTMEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, macros, device):\n",
    "        \n",
    "        super(MatchLSTMEncoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = macros['hidden_dim']\n",
    "        self.ques_len = macros['ques_len']\n",
    "        self.batch_size = macros['batch_size']\n",
    "        self.debug = macros['debug']    \n",
    "        \n",
    "        # Catch lens and params\n",
    "        self.lin_g_repeat_a_dense = nn.Linear(2*self.hidden_dim, self.hidden_dim)\n",
    "        self.lin_g_repeat_b_dense = nn.Linear(self.hidden_dim, self.hidden_dim, bias=False)\n",
    "        self.lin_g_nobias = nn.Linear(2*self.hidden_dim, self.hidden_dim, bias=False)\n",
    "        \n",
    "        self.alpha_i_w = nn.Parameter(torch.rand((self.hidden_dim, 1)))\n",
    "        self.alpha_i_b = nn.Parameter(torch.rand((1)))\n",
    "        \n",
    "        self.lstm_summary = nn.LSTM((self.ques_len+1)*2*self.hidden_dim, self.hidden_dim, batch_first=False)\n",
    "                                      \n",
    "    \n",
    "    def forward(self, H_p, h_ri, H_q, hidden, device):\n",
    "        \"\"\"\n",
    "            Ideally, we would have manually unrolled the lstm \n",
    "            but due to memory constraints, we do it in the module.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Find the batchsize\n",
    "        batch_size = H_p.shape[1]\n",
    "        \n",
    "        H_r = torch.empty((0, batch_size, self.hidden_dim), device=device, dtype=torch.float)\n",
    "        H_r = torch.cat((H_r, h_ri), dim=0)\n",
    "        \n",
    "        if self.debug > 4:\n",
    "            print( \"H_p:\\t\\t\\t\", H_p.shape)\n",
    "            print( \"H_q:\\t\\t\\t\", H_q.shape)\n",
    "            print( \"h_ri:\\t\\t\\t\", h_ri.shape)\n",
    "            print( \"H_r:\\t\\t\\t\", H_r.shape)\n",
    "            print( \"hid:\\t\\t\\t\", hidden.shape)\n",
    "        \n",
    "        for i in range(H_p.shape[0]):\n",
    "            \n",
    "            # We call the (W^P.H^P + W^rh^r_i-1 + b^P) as lin_repeat_input.\n",
    "            \n",
    "            # We first write out its two components as\n",
    "            lin_repeat_input_a = self.lin_g_repeat_a_dense(H_p[i].view(1, batch_size, -1))\n",
    "            if self.debug > 4: print(\"lin_repeat_input_a:\\t\", lin_repeat_input_a.shape)\n",
    "            \n",
    "            lin_repeat_input_b = self.lin_g_repeat_b_dense(H_r[i].view(1, batch_size, -1))\n",
    "            if self.debug > 4: print(\"lin_repeat_input_b:\\t\", lin_repeat_input_b.shape)\n",
    "            \n",
    "            # Add the two terms up\n",
    "            lin_repeat_input_a.add_(lin_repeat_input_b)\n",
    "#             if self.debug > 4: print(\"lin_g_input_b unrepeated:\", lin_g_input_b.shape)\n",
    "\n",
    "            lin_g_input_b = lin_repeat_input_a.repeat(H_q.shape[0], 1, 1)\n",
    "            if self.debug > 4: print(\"lin_g_input_b:\\t\\t\", lin_g_input_b.shape)\n",
    "\n",
    "            # lin_g_input_a = self.lin_g_nobias.matmul(H_q.view(-1, self.ques_len, self.hidden_dim)) #self.lin_g_nobias(H_q)\n",
    "            lin_g_input_a =  self.lin_g_nobias(H_q)\n",
    "            if self.debug > 4: print(\"lin_g_input_a:\\t\\t\", lin_g_input_a.shape)\n",
    "\n",
    "            G_i = F.tanh(lin_g_input_a + lin_g_input_b)\n",
    "            if self.debug > 4: print(\"G_i:\\t\\t\\t\", G_i.shape)\n",
    "            # Note; G_i should be a 1D vector over ques_len\n",
    "            \n",
    "            # Attention weights\n",
    "            alpha_i_input_a = G_i.transpose(1,0).matmul(self.alpha_i_w).view(batch_size, 1, -1)\n",
    "            if self.debug > 4: print(\"alpha_i_input_a:\\t\", alpha_i_input_a.shape)\n",
    "\n",
    "            alpha_i_input = alpha_i_input_a.add_(self.alpha_i_b.view(-1,1,1).repeat(1,1,self.ques_len))\n",
    "            if self.debug > 4: print(\"alpha_i_input:\\t\\t\", alpha_i_input.shape)\n",
    "\n",
    "            # Softmax over alpha inputs\n",
    "            alpha_i = F.softmax(alpha_i_input, dim=-1)\n",
    "            if self.debug > 4: print(\"alpha_i:\\t\\t\", alpha_i.shape)  \n",
    "                \n",
    "            # Weighted summary of question with alpha    \n",
    "            z_i_input_b = (\n",
    "                            H_q.transpose(1, 0) *\n",
    "                           (alpha_i.view(batch_size, self.ques_len, -1).repeat(1, 1, 2*self.hidden_dim))\n",
    "                          ).transpose(1, 0)\n",
    "            if self.debug > 4: print(\"z_i_input_b:\\t\\t\", z_i_input_b.shape)\n",
    "\n",
    "            z_i = torch.cat((H_p[i].view(1, batch_size, -1), z_i_input_b), dim=0)\n",
    "            if self.debug > 4: print(\"z_i:\\t\\t\\t\", z_i.shape)\n",
    "\n",
    "            # Take input from LSTM, concat in H_r and nullify the temp var.                \n",
    "            h_ri, (_, hidden) = self.lstm_summary(z_i.transpose(1,0).contiguous().view(1, batch_size, -1), \n",
    "                                             (H_r[i].view(1,batch_size, -1), hidden))\n",
    "            if self.debug > 4:\n",
    "                print(\"newh_ri:\\t\\t\", h_ri.shape)\n",
    "                print(\"newhidden:\\t\\t\", hidden.shape)\n",
    "            H_r = torch.cat((H_r, h_ri), dim=0)\n",
    "            \n",
    "            if self.debug > 4:\n",
    "                print(\"\\tH_r:\\t\\t\\t\", H_r.shape)\n",
    "\n",
    "        return H_r[1:]\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return torch.zeros((1, batch_size, self.hidden_dim), device=device)\n",
    "#                 torch.zeros((1, batch_size, self.hidden_dim), device=device))\n",
    "\n",
    "\n",
    "\n",
    "if DEBUG > 4:\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        macros = {\n",
    "            \"ques_len\": QUES_LEN,\n",
    "            \"hidden_dim\": HIDDEN_DIM, \n",
    "            \"vocab_size\": VOCAB_SIZE, \n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"para_len\": PARA_LEN,\n",
    "            \"embedding_dim\": EMBEDDING_DIM,\n",
    "            \"lr\": LR,\n",
    "            \"debug\":5,\n",
    "            \"device\":device\n",
    "        }\n",
    "            \n",
    "        matchLSTMEncoder = MatchLSTMEncoder(macros,device).cuda(device)\n",
    "        hidden = matchLSTMEncoder.init_hidden(BATCH_SIZE,device)\n",
    "        para_embedded = torch.rand((PARA_LEN, BATCH_SIZE, 2*HIDDEN_DIM), device=device)\n",
    "        ques_embedded = torch.rand((QUES_LEN, BATCH_SIZE, 2*HIDDEN_DIM), device=device)\n",
    "        h_ri = torch.randn(1, BATCH_SIZE, HIDDEN_DIM, device=device)\n",
    "    #     if DEBUG:\n",
    "    #         print (\"init h_ri shape is: \", h_ri.shape)\n",
    "    #         print (\"the para length is \", len(para_embedded))\n",
    "        H_r = matchLSTMEncoder(para_embedded.view(-1,BATCH_SIZE,2*HIDDEN_DIM),\n",
    "                               h_ri, \n",
    "                               ques_embedded, \n",
    "                               hidden,\n",
    "                               device)\n",
    "        print(\"H_r: \", H_r.shape)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointer Network\n",
    "\n",
    "Using a ptrnet over $H_r$ to unfold and get most probable spans.\n",
    "We use the **boundry model** to do that (predict start and end of seq).\n",
    "\n",
    "A simple energy -> softmax -> decoder. Where softmaxed energy is supervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PointerDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, macros, device):\n",
    "        super(PointerDecoder, self).__init__()\n",
    "        \n",
    "        # Keep args\n",
    "        self.hidden_dim = macros['hidden_dim']\n",
    "        self.batch_size = macros['batch_size']\n",
    "        self.para_len = macros['para_len']\n",
    "        self.debug = macros['debug']\n",
    "        \n",
    "        self.lin_f_repeat = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.lin_f_nobias = nn.Linear(self.hidden_dim, self.hidden_dim, bias=False)\n",
    "        \n",
    "        self.beta_k_w = nn.Parameter(torch.randn(self.hidden_dim, 1))\n",
    "        self.beta_k_b = nn.Parameter(torch.randn(1))\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.hidden_dim*self.para_len, self.hidden_dim, batch_first=False)\n",
    "\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return torch.zeros((1, batch_size, self.hidden_dim), device=device)\n",
    "#                 torch.zeros((1, batch_size, self.hidden_dim), device=device))\n",
    "    \n",
    "    def forward(self, h_ak, H_r, hidden, device):\n",
    "        \n",
    "        # h_ak (current decoder's last op) (1,batch,hiddendim)\n",
    "        # H_r (weighted summary of para) (P, batch, hiddendim)\n",
    "        batch_size = H_r.shape[1]\n",
    "        \n",
    "        if self.debug > 4:\n",
    "            print(\"h_ak:\\t\\t\\t\", h_ak.shape)\n",
    "            print(\"H_r:\\t\\t\\t\", H_r.shape)\n",
    "            print(\"hidden:\\t\\t\\t\", hidden.shape)\n",
    "            \n",
    "        # Prepare inputs for the tanh used to compute energy\n",
    "        f_input_b = self.lin_f_repeat(h_ak)\n",
    "        if self.debug > 4: print(\"f_input_b unrepeated:  \", f_input_b.shape)\n",
    "        \n",
    "        #H_r shape is ([PARA_LEN, BATCHSIZE, EmbeddingDIM])\n",
    "        f_input_b = f_input_b.repeat(H_r.shape[0], 1, 1)\n",
    "        if self.debug > 4: print(\"f_input_b repeated:\\t\", f_input_b.shape)\n",
    "            \n",
    "        f_input_a = self.lin_f_nobias(H_r)\n",
    "        if self.debug > 4: print(\"f_input_a:\\t\\t\", f_input_a.shape)\n",
    "            \n",
    "        # Send it off to tanh now\n",
    "        F_k = F.tanh(f_input_a+f_input_b)\n",
    "        if self.debug > 4: print(\"F_k:\\t\\t\\t\", F_k.shape) #PARA_LEN,BATCHSIZE,EmbeddingDim\n",
    "        \n",
    "        # Attention weights\n",
    "        beta_k_input_a = F_k.transpose(1,0).matmul(self.beta_k_w).view(batch_size, 1, -1)\n",
    "        if self.debug > 4: print(\"beta_k_input_a:\\t\\t\", beta_k_input_a.shape)\n",
    "            \n",
    "        beta_k_input = beta_k_input_a.add_(self.beta_k_b.repeat(1,1,self.para_len))\n",
    "        if self.debug > 4: print(\"beta_k_input:\\t\\t\", beta_k_input.shape)\n",
    "            \n",
    "        beta_k = F.softmax(beta_k_input, dim=-1)\n",
    "        if self.debug > 4: print(\"beta_k:\\t\\t\\t\", beta_k.shape)\n",
    "        \n",
    "        lstm_input_a = H_r.transpose(1,0) * (beta_k.view(batch_size, self.para_len, -1).repeat(1,1,self.hidden_dim))\n",
    "        if self.debug > 4: print(\"lstm_input_a:\\t\\t\", lstm_input_a.shape)\n",
    "        \n",
    "        h_ak, (_, hidden) = self.lstm(lstm_input_a.transpose(1,0).contiguous().view(1, batch_size, -1), (h_ak, hidden))\n",
    "        \n",
    "        return h_ak, hidden, F.log_softmax(beta_k_input, dim=-1)\n",
    "            \n",
    "if DEBUG > 4:\n",
    "    with torch.no_grad():\n",
    "        macros = {\n",
    "            \"ques_len\": QUES_LEN,\n",
    "            \"hidden_dim\": HIDDEN_DIM, \n",
    "            \"vocab_size\": VOCAB_SIZE, \n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"para_len\": PARA_LEN,\n",
    "            \"embedding_dim\": EMBEDDING_DIM,\n",
    "            \"lr\": LR,\n",
    "            \"debug\":5,\n",
    "            \"device\":device\n",
    "        }\n",
    "        \n",
    "        pointerDecoder = PointerDecoder(macros, device).cuda(device)\n",
    "        h_ak = torch.randn(1,BATCH_SIZE,HIDDEN_DIM, device=device)\n",
    "        H_r = torch.randn(PARA_LEN, BATCH_SIZE, HIDDEN_DIM, device=device)\n",
    "        hidden = pointerDecoder.init_hidden(BATCH_SIZE, device)\n",
    "        h_ak, hidden, beta_k = pointerDecoder(h_ak, H_r, hidden, device)\n",
    "        print (beta_k.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull the real data from disk.\n",
    "\n",
    "Files stored in `./data/squad/train.ids.*`\n",
    "Pull both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_loc, macros, crop=None):\n",
    "    \"\"\"\n",
    "        Given the dataloc and the data available in a specific format, it would pick the data up, and make trainable matrices,\n",
    "        Harvest train_P, train_Q, train_Y, test_P, test_Q, test_Y matrices in this format\n",
    "        \n",
    "        If crop given, will trim the data at a certain length\n",
    "        \n",
    "        **return_type**: np matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpacking macros\n",
    "    PARA_LEN = macros['para_len']\n",
    "    QUES_LEN = macros['ques_len']\n",
    "    \n",
    "    train_q = np.asarray([[int(x) for x in datum.split()] for datum in list(open(os.path.join(data_loc, 'train.ids.question')))])\n",
    "    train_p = np.asarray([[int(x) for x in datum.split()] for datum in list(open(os.path.join(data_loc, 'train.ids.context')))])\n",
    "    train_y = np.asarray([[int(x) for x in datum.split()] for datum in list(open(os.path.join(data_loc, 'train.span')))])\n",
    "\n",
    "    test_q = np.asarray([[int(x) for x in datum.split()] for datum in list(open(os.path.join(data_loc, 'val.ids.question')))])\n",
    "    test_p = np.asarray([[int(x) for x in datum.split()] for datum in list(open(os.path.join(data_loc, 'val.ids.context')))])\n",
    "    test_y = np.asarray([[int(x) for x in datum.split()] for datum in list(open(os.path.join(data_loc, 'val.span')))])\n",
    "\n",
    "    if macros['debug'] > 3:\n",
    "        print(\"Train Q: \", train_q.shape)\n",
    "        print(\"Train P: \", train_p.shape)\n",
    "        print(\"Train Y: \", train_y.shape)\n",
    "        print(\"Test Q: \", test_q.shape)\n",
    "        print(\"Test P: \", test_p.shape)\n",
    "        print(\"Test Y: \", test_y.shape)\n",
    "    \n",
    "    \"\"\"\n",
    "        Parse the semi-raw data:\n",
    "            - shuffle\n",
    "            - pad, prepare\n",
    "            - dump useless vars\n",
    "    \"\"\"\n",
    "    # Shuffle data\n",
    "    \n",
    "    if crop:\n",
    "        index_train, index_test = np.random.choice(np.arange(len(train_p)), crop), \\\n",
    "                                  np.random.choice(np.arange(len(test_p)), crop)\n",
    "    else:\n",
    "        index_train, index_test = np.arange(len(train_p)), np.arange(len(test_p))\n",
    "        np.random.shuffle(index_train)\n",
    "        np.random.shuffle(index_test)\n",
    "\n",
    "    train_p, train_q, train_y = train_p[index_train], train_q[index_train], train_y[index_train]\n",
    "    test_p, test_q, test_y = test_p[index_test], test_q[index_test], test_y[index_test]\n",
    "\n",
    "#     sanity_check(train_p, train_y)\n",
    "\n",
    "    if macros['debug'] >= 5:\n",
    "        print(\"Max q len: \", max(len(q) for q in train_q))\n",
    "        \n",
    "    \n",
    "    # Pad and prepare\n",
    "    train_P = np.zeros((len(train_p), PARA_LEN))\n",
    "    train_Q = np.zeros((len(train_q), QUES_LEN))\n",
    "    train_Y_start = np.zeros((len(train_p), PARA_LEN))\n",
    "    train_Y_end = np.zeros((len(train_p), PARA_LEN))\n",
    "\n",
    "    test_P = np.zeros((len(test_p), PARA_LEN))\n",
    "    test_Q = np.zeros((len(test_q), QUES_LEN))\n",
    "    test_Y_start = np.zeros((len(test_p), PARA_LEN))\n",
    "    test_Y_end = np.zeros((len(test_p), PARA_LEN))\n",
    "    \n",
    "#     print(train_P.shape)\n",
    "\n",
    "    crop_train = []    # Remove these rows from training\n",
    "    for i in range(len(train_p)):\n",
    "        p = train_p[i]\n",
    "        q = train_q[i]\n",
    "        y = train_y[i]\n",
    "        \n",
    "        # First see if you can keep this example or not (due to size)\n",
    "        if y[0] >= PARA_LEN or y[1] >= PARA_LEN:\n",
    "            crop_train.append(i)\n",
    "            continue\n",
    "\n",
    "\n",
    "        train_P[i, :min(PARA_LEN, len(p))] = p[:min(PARA_LEN, len(p))]\n",
    "        train_Q[i, :min(QUES_LEN, len(q))] = q[:min(QUES_LEN, len(q))]\n",
    "        train_Y_start[i, y[0]] = 1\n",
    "        train_Y_end[i, y[1]] = 1\n",
    "\n",
    "    crop_test = []\n",
    "    for i in range(len(test_p)):\n",
    "        p = test_p[i]\n",
    "        q = test_q[i]\n",
    "        y = test_y[i]\n",
    "\n",
    "        # First see if you can keep this example or not (due to size)\n",
    "        if y[0] >= PARA_LEN or y[1] >= PARA_LEN:\n",
    "            crop_test.append(i)\n",
    "            continue\n",
    "\n",
    "        test_P[i, :min(PARA_LEN, len(p))] = p[:min(PARA_LEN, len(p))]\n",
    "        test_Q[i, :min(QUES_LEN, len(q))] = q[:min(QUES_LEN, len(q))]\n",
    "        test_Y_start[i, y[0]] = 1\n",
    "        test_Y_end[i, y[1]] = 1\n",
    "        \n",
    "        \n",
    "    # Remove the instances which are in crop_train\n",
    "    train_P = np.delete(train_P, crop_train, axis=0)\n",
    "    train_Q = np.delete(train_Q, crop_train, axis=0)\n",
    "    train_Y_start = np.delete(train_Y_start, crop_train, axis=0)\n",
    "    train_Y_end = np.delete(train_Y_end, crop_train, axis=0)\n",
    "    \n",
    "    test_P = np.delete(test_P, crop_test, axis=0)\n",
    "    test_Q = np.delete(test_Q, crop_test, axis=0)\n",
    "    test_Y_start = np.delete(test_Y_start, crop_test, axis=0)\n",
    "    test_Y_end = np.delete(test_Y_end, crop_test, axis=0)\n",
    "\n",
    "    if macros['debug'] >= 1:\n",
    "        print(\"Train Q: \", train_Q.shape)\n",
    "        print(\"Train P: \", train_P.shape)\n",
    "        print(\"Train Y: \", train_Y_start.shape)\n",
    "        print(\"Test Q: \", test_Q.shape)\n",
    "        print(\"Test P: \", test_P.shape)\n",
    "        print(\"Test Y: \", test_Y_start.shape)\n",
    "        print(\"Crop_train: \", len(crop_train))\n",
    "        print(\"Crop_test: \", len(crop_test))\n",
    "    # Let's free up some memory now\n",
    "    train_p, train_q, train_y, test_p, test_q, test_y = None, None, None, None, None, None\n",
    "    \n",
    "    # Load embedding matrics\n",
    "    vectors = np.load(os.path.join(data_loc, 'glove.new.trimmed.300.npy'))\n",
    "    \n",
    "    return train_P, train_Q, train_Y_start, train_Y_end, test_P, test_Q, test_Y_start, test_Y_end, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macros = {\n",
    "#     \"ques_len\": QUES_LEN,\n",
    "#     \"hidden_dim\": HIDDEN_DIM, \n",
    "#     \"vocab_size\": VOCAB_SIZE, \n",
    "#     \"batch_size\": BATCH_SIZE,\n",
    "#     \"para_len\": PARA_LEN,\n",
    "#     \"embedding_dim\": EMBEDDING_DIM,\n",
    "#     \"debug\": 5\n",
    "# } \n",
    "\n",
    "# a = prepare_data(DATA_LOC, macros=macros, crop=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, and running the model\n",
    "- Write a train fn\n",
    "- Write a training loop invoking it\n",
    "- Fill in real data\n",
    "\n",
    "----------\n",
    "\n",
    "Feats:\n",
    "- Function to test every n epochs.\n",
    "- Report train accuracy every epoch\n",
    "- Store the train, test accuracy for every instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model\n",
    "def save_model(loc, models, epochs=0, optimizer=None):\n",
    "    \"\"\"\n",
    "        Input:\n",
    "            loc: str of the folder where the models are to be saved\n",
    "            models: dict of 'model_name': model_object\n",
    "            epochs, optimizers are int, torch.optims (discarded right now).\n",
    "    \"\"\"\n",
    "    \n",
    "    assert type(models) is dict and len(models.keys()) == 4\n",
    "    \n",
    "    # Assumes four models. Doesn't save device/epochs/optimizer right now.\n",
    "    \n",
    "    for name in models:\n",
    "        torch.save(models[name], os.path.join(loc, name+'.torch'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(para_batch,\n",
    "          ques_batch,\n",
    "          answer_start_batch,\n",
    "          answer_end_batch,\n",
    "          ques_model,\n",
    "          para_model,\n",
    "          mlstm_model,\n",
    "          pointer_decoder_model,\n",
    "          optimizer, \n",
    "          loss_fn,\n",
    "          macros,\n",
    "          debug=2):\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    :param para_batch: paragraphs (batch, max_seq_len_para) \n",
    "    :param ques_batch: questions corresponding to para (batch, max_seq_len_ques)\n",
    "    :param answer_start_batch: one-hot vector denoting pos of span start (batch, max_seq_len_para)\n",
    "    :param answer_end_batch: one-hot vector denoting pos of span end (batch, max_seq_len_para)\n",
    "    \n",
    "    # Models\n",
    "    :param ques_model: model to encode ques\n",
    "    :param para_model: model to encode para\n",
    "    :param mlstm_model: model to match para, ques to get para summary\n",
    "    :param pointer_decoder_model: model to get a pointer over start and end span pointer\n",
    "    \n",
    "    # Loss and Optimizer.\n",
    "    :param loss_fn: \n",
    "    :param optimizer: \n",
    "    \n",
    "    :return: \n",
    "    \n",
    "    \n",
    "    NOTE: When using MSE, \n",
    "        - target labels are one-hot\n",
    "        - target label is float tensor\n",
    "        - shape (batch, 1, len)\n",
    "        \n",
    "        When using CrossEntropy\n",
    "        - target is not onehot\n",
    "        - long\n",
    "        - shape (batch, )\n",
    "    \"\"\"\n",
    "    try:    \n",
    "    #     DEBUG = debug\n",
    "    #     BATCH_SIZE = macros['batch_size']\n",
    "    #     HIDDEN_DIM = macros['hidden_dim']\n",
    "\n",
    "        if debug >=2: \n",
    "            print(\"\\tpara_batch:\\t\\t\", para_batch.shape)\n",
    "            print(\"\\tques_batch:\\t\\t\", ques_batch.shape)\n",
    "            print(\"\\tanswer_start_batch:\\t\", answer_start_batch.shape)\n",
    "            print(\"\\tanswer_end_batch:\\t\\t\", answer_end_batch.shape)\n",
    "\n",
    "        # Wiping all gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Initializing all hidden states.\n",
    "        hidden_quesenc = ques_model.init_hidden(macros['batch_size'], device)\n",
    "        hidden_paraenc = para_model.init_hidden(macros['batch_size'], device)\n",
    "        hidden_mlstm = mlstm_model.init_hidden(macros['batch_size'], device)\n",
    "        hidden_ptrnet = pointer_decoder_model.init_hidden(macros['batch_size'], device)\n",
    "        h_ri = torch.zeros((1, macros['batch_size'], macros['hidden_dim']), dtype=torch.float, device=device)\n",
    "        h_ak = torch.zeros((1, macros['batch_size'], macros['hidden_dim']), dtype=torch.float, device=device)\n",
    "        if debug >= 2: print(\"------------Instantiated hidden states------------\")\n",
    "\n",
    "        #passing the data through LSTM pre-processing layer\n",
    "        H_q, ques_model_hidden = ques_model(ques_batch, hidden_quesenc, device=device)\n",
    "        H_p, para_model_hidden = para_model(para_batch, hidden_paraenc, device=device)\n",
    "        if debug >= 2: \n",
    "            print(\"\\tH_q:\\t\\t\", H_q.shape)\n",
    "            print(\"\\tH_p:\\t\\t\", H_p.shape)\n",
    "            print(\"\\tH_ri:\\t\\t\", h_ri.shape)\n",
    "    #         raw_input(\"Check memory and ye shall continue\")\n",
    "            print(\"------------Encoded hidden states------------\")\n",
    "\n",
    "        H_r = mlstm_model(H_p.view(-1, macros['batch_size'], 2*macros['hidden_dim']), h_ri, H_q, hidden_mlstm, device=device)\n",
    "        if debug >= 2: print(\"------------Passed through matchlstm------------\")\n",
    "\n",
    "        #Passing the paragraph embddin via pointer network to generate final answer pointer.\n",
    "        h_ak, hidden_ptrnet, beta_k_start = pointer_decoder_model(h_ak, H_r, hidden_ptrnet, device=device)\n",
    "        h_ak, hidden_ptrnet, beta_k_end = pointer_decoder_model(h_ak, H_r, hidden_ptrnet, device=device)\n",
    "        if debug >= 2: print(\"------------Passed through pointernet------------\")\n",
    "\n",
    "\n",
    "        # For crossentropy\n",
    "        _, answer_start_batch = answer_start_batch.max(dim=2)\n",
    "        _, answer_end_batch = answer_end_batch.max(dim=2)\n",
    "        answer_start_batch = answer_start_batch.view(-1).long()\n",
    "        answer_end_batch = answer_end_batch.view(-1).long()\n",
    "#         print(beta_k_start.view(-1, macros['para_len']).shape, answer_start_batch.view(-1).shape)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        loss = loss_fn(beta_k_start.view(-1, macros['para_len']), answer_start_batch)\n",
    "        loss += loss_fn(beta_k_end.view(-1, macros['para_len']), answer_end_batch)\n",
    "#         loss = loss_fn(beta_k_start, answer_start_batch)\n",
    "#         loss += loss_fn(beta_k_end, answer_end_batch)\n",
    "        if debug >= 2: print(\"------------Calculated loss------------\")\n",
    "\n",
    "        loss.backward()\n",
    "        if debug >= 2: print(\"------------Calculated Gradients------------\")\n",
    "\n",
    "        #optimization step\n",
    "        optimizer.step()\n",
    "        if debug >= 2: print(\"------------Updated weights.------------\")\n",
    "            \n",
    "        return beta_k_start, beta_k_end, loss\n",
    "    \n",
    "    except: \n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function (no grad, no eval)\n",
    "def predict(para_batch,\n",
    "            ques_batch,\n",
    "            ques_model,\n",
    "            para_model,\n",
    "            mlstm_model,\n",
    "            pointer_decoder_model,\n",
    "            macros,\n",
    "            loss_fn=None,\n",
    "            debug=DEBUG):\n",
    "    \"\"\"\n",
    "        Function which returns the model's output based on a given set of P&Q's. \n",
    "        Does not convert to strings, gives the direct model output.\n",
    "        \n",
    "        Expects:\n",
    "            four models\n",
    "            data\n",
    "            misc macros\n",
    "    \"\"\"\n",
    "    \n",
    "#     BATCH_SIZE = macros['batch_size']\n",
    "    BATCH_SIZE = ques_batch.shape[0]\n",
    "    HIDDEN_DIM = macros['hidden_dim']\n",
    "    DEBUG = debug\n",
    "    \n",
    "    if debug >=2: \n",
    "        print(\"\\tpara_batch:\\t\\t\", para_batch.shape)\n",
    "        print(\"\\tques_batch:\\t\\t\", ques_batch.shape)\n",
    "        \n",
    "    with torch.no_grad():    \n",
    "\n",
    "        # Initializing all hidden states.\n",
    "        hidden_quesenc = ques_model.init_hidden(BATCH_SIZE, device)\n",
    "        hidden_paraenc = para_model.init_hidden(BATCH_SIZE, device)\n",
    "        hidden_mlstm = mlstm_model.init_hidden(BATCH_SIZE, device)\n",
    "        hidden_ptrnet = pointer_decoder_model.init_hidden(BATCH_SIZE, device)\n",
    "        h_ri = torch.zeros((1, BATCH_SIZE, HIDDEN_DIM), dtype=torch.float, device=device)\n",
    "        h_ak = torch.zeros((1, BATCH_SIZE, HIDDEN_DIM), dtype=torch.float, device=device)\n",
    "        if DEBUG >= 2: print(\"------------Instantiated hidden states------------\")\n",
    "            \n",
    "        #passing the data through LSTM pre-processing layer\n",
    "        H_q, ques_model_hidden = ques_model(ques_batch, hidden_quesenc, device)\n",
    "        H_p, para_model_hidden = para_model(para_batch, hidden_paraenc, device)\n",
    "        if DEBUG >= 2: \n",
    "            print(\"\\tH_q:\\t\\t\", H_q.shape)\n",
    "            print(\"\\tH_p:\\t\\t\", H_p.shape)\n",
    "            print(\"\\tH_ri:\\t\\t\", h_ri.shape)\n",
    "#             raw_input(\"Check memory and ye shall continue\")\n",
    "            print(\"------------Encoded hidden states------------\")\n",
    "\n",
    "        H_r = mlstm_model(H_p.view(-1, BATCH_SIZE, 2*HIDDEN_DIM), h_ri, H_q, hidden_mlstm, device)\n",
    "        if DEBUG >= 2: print(\"------------Passed through matchlstm------------\")\n",
    "\n",
    "        #Passing the paragraph embddin via pointer network to generate final answer pointer.\n",
    "        h_ak, hidden_ptrnet, beta_k_start = pointer_decoder_model(h_ak, H_r, hidden_ptrnet, device)\n",
    "        _, _, beta_k_end = pointer_decoder_model(h_ak, H_r, hidden_ptrnet, device)\n",
    "        if DEBUG >= 2: print(\"------------Passed through pointernet------------\")\n",
    "                            \n",
    "        # For crossentropy\n",
    "#         _, answer_start_batch = answer_start_batch.max(dim=2)[1]\n",
    "#         _, answer_end_batch = answer_end_batch.max(dim=2)[1]\n",
    "#         print(\"labels: \", answer_start_batch.shape)[1]\n",
    "            \n",
    "#         #How will we manage batches for loss.\n",
    "#         loss = loss_fn(beta_k_start, answer_start_batch)\n",
    "#         loss += loss_fn(beta_k_end, answer_end_batch)\n",
    "#         if debug >= 2: print(\"------------Calculated loss------------\")\n",
    "            \n",
    "        return (beta_k_start, beta_k_end, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'em': 0.5, u'p': 1.0, u'r': 0.75, u'f1': 0.8571428571428571}\n"
     ]
    }
   ],
   "source": [
    "# Eval function (no grad no eval no nothing)\n",
    "def eval(y_cap, y, metrics={'em':None, 'p':None, 'r':None, 'f1':None}):\n",
    "    \"\"\" \n",
    "        Returns the exact-match (em) metric by default.\n",
    "        Can specifiy more in a list (TODO)\n",
    "        \n",
    "        Inputs:\n",
    "        - y_cap: list of two tensors (start, end) of dim [BATCH_SIZE, PARA_LEN] each\n",
    "        - y: list of two tensors (start, end) of dim [BATCH_SIZE, 1] each\n",
    "    \"\"\"\n",
    "    \n",
    "#     y_cap= torch.argmax(y_cap[0], dim=1).float(), torch.argmax(y_cap[1], dim=1).float()\n",
    "#     y = torch.argmax(y[0], dim=1).float(), torch.argmax(y[1], dim=1).float()\n",
    "    \n",
    "    \n",
    "    # If we want f1 and haven't specified that we want p and q, fuck it and add it there\n",
    "    if 'f1' in metrics.keys():\n",
    "        metrics['p'] = None \n",
    "        metrics['r'] = None\n",
    "    \n",
    "    # Convert to numpy arrays of size (batch, 2)\n",
    "    y_cap= np.vstack((torch.argmax(y_cap[0], dim=1).float().data, torch.argmax(y_cap[1], dim=1).float().data)).transpose()\n",
    "    y = np.vstack((torch.argmax(y[0], dim=1).float().data, torch.argmax(y[1], dim=1).float().data)).transpose()\n",
    "      \n",
    "    # First, if start > end, fix that (we're cool that way.)\n",
    "    for i in range(y_cap.shape[0]):\n",
    "        if y_cap[i][0] > y_cap[i][1]: \n",
    "            y_cap[i] = y_cap[i][[1,0]]\n",
    "            \n",
    "    if 'f1' in metrics.keys():\n",
    "        \n",
    "        intersection = np.min((y[:,1], y_cap[:,1]), axis=0)-np.max((y[:,0], y_cap[:,0]), axis=0)\n",
    "        intersection[intersection<0] = 0\n",
    "        intersection =  intersection.astype(np.float)\n",
    "        \n",
    "        positives = y_cap[:,1] - y_cap[:,0]\n",
    "        truth = y[:,1] - y[:,0]\n",
    "        \n",
    "        p = np.mean(intersection/positives)\n",
    "        r = np.mean(intersection/truth)\n",
    "        \n",
    "        metrics['p'] = p\n",
    "        metrics['r'] = r\n",
    "        \n",
    "        # f1\n",
    "        # If p or r is zero, f1 is zero\n",
    "        if p > 0 and r > 0:\n",
    "            metrics['f1'] = 2*p*r/(p+r)\n",
    "        else:\n",
    "            metrics['f1'] = 0.0\n",
    "    \n",
    "    else:\n",
    "        if 'p' in metric.keys():\n",
    "            \n",
    "            intersection = np.min((y[:,1], y_cap[:,1]), axis=0)-np.max((y[:,0], y_cap[:,0]), axis=0)\n",
    "            intersection[intersection<0] = 0\n",
    "            intersection =  intersection.astype(np.float)\n",
    "\n",
    "            positives = y_cap[:,1] - y_cap[:,0]\n",
    "\n",
    "            p = np.mean(intersection/positives)\n",
    "\n",
    "            metrics['p'] = p\n",
    "            \n",
    "        if 'r'  in metric.keys():\n",
    "\n",
    "            intersection = np.min((y[:,1], y_cap[:,1]), axis=0)-np.max((y[:,0], y_cap[:,0]), axis=0)\n",
    "            intersection[intersection<0] = 0\n",
    "            intersection =  intersection.astype(np.float)\n",
    "\n",
    "            truth = y[:,1] - y[:,0]\n",
    "\n",
    "            r = np.mean(intersection/truth)\n",
    "\n",
    "            metrics['r'] = r\n",
    "\n",
    "    if \"em\" in metrics.keys():\n",
    "        metrics['em'] = np.mean(np.logical_and(np.equal(y[:,0], y_cap[:,0]),np.equal(y[:,1], y_cap[:,1])))\n",
    "        \n",
    "    if DEBUG >= 3: \n",
    "        print(\"Test performance: \", metrics)\n",
    "        print(\"------------Evaluated------------\")\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "if True:\n",
    "    # Testing this function\n",
    "    metrics = {'em':None}\n",
    "#     y = torch.tensor([[3]]).float(), torch.tensor([[4]]).float()\n",
    "    y = torch.tensor([[0,0,3,0], [0,2,0,0]]), torch.tensor([[0,0,0,3], [0,0,0,3]])\n",
    "    y_cap = torch.tensor([[0,0,3,0],[0,0,3,0]]), torch.tensor([[0,0,0,3],[0,0,0,3]])\n",
    "#     y = torch.randint(0, PARA_LEN, (BATCH_SIZE,)).float(), torch.randint(0, PARA_LEN, (BATCH_SIZE,)).float()\n",
    "#     y_cap = torch.rand((BATCH_SIZE, PARA_LEN)), torch.rand((BATCH_SIZE, PARA_LEN))\n",
    "    print(eval(y_cap, y))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(_models, _data, _macros, _epochs, _save=0, _test_eval=0, _train_eval=0, _debug=2):\n",
    "    \"\"\"\n",
    "        > Instantiate models\n",
    "        > Instantiate loss, optimizer\n",
    "        > Instantiate ways to store loss\n",
    "\n",
    "        > Per epoch\n",
    "            > sample batch and give to train fn\n",
    "            > get loss\n",
    "            > if epoch %k ==0: get test accuracy\n",
    "\n",
    "        > have fn to calculate test accuracy\n",
    "        \n",
    "        > _save: int\n",
    "            > 0: dont\n",
    "            > 1+: save every _save epoch (overwrite)\n",
    "            > -1 -> save best (turned to 1 if test evals dont happen.)\n",
    "        \n",
    "        > Save the model at every epoch if we don't test on test. \n",
    "            > else save on the best performning mode\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack data\n",
    "    DEBUG = _debug\n",
    "    train_P = _data['train']['P']\n",
    "    train_Q = _data['train']['Q']\n",
    "    train_Y_start = _data['train']['Ys']\n",
    "    train_Y_end = _data['train']['Ye']\n",
    "    test_P = _data['test']['P']\n",
    "    test_Q = _data['test']['Q']\n",
    "    test_Y_start = _data['test']['Ys']\n",
    "    test_Y_end = _data['test']['Ye']\n",
    "\n",
    "    ques_model, para_model, mlstm_model, pointer_decoder_model = _models\n",
    "    _data = None\n",
    "\n",
    "    # Instantiate Loss\n",
    "#         loss_fn = nn.MSELoss()\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(list(filter(lambda p: p.requires_grad, ques_model.parameters())) + \n",
    "                             list(filter(lambda p: p.requires_grad, para_model.parameters())) + \n",
    "                             list(mlstm_model.parameters()) + \n",
    "                             list(pointer_decoder_model.parameters()), lr=macros['lr'])\n",
    "#         optimizer = optim.Adam(list(ques_model.parameters()) + \\\n",
    "#                                list(para_model.parameters()) + \\\n",
    "#                                list(mlstm_model.parameters()) + \\\n",
    "#                               list(pointer_decoder_model.parameters()), lr=macros['lr'])\n",
    "\n",
    "    # Losses\n",
    "    train_losses = []\n",
    "    train_em = []\n",
    "    test_losses = []\n",
    "    test_em = []\n",
    "    best_test_em = 0.0\n",
    "    found_best_test_em = False\n",
    "    \n",
    "    try: \n",
    "\n",
    "        # Training Loop\n",
    "        for epoch in range(_epochs):\n",
    "            print(\"Epoch: \", epoch, \"/\", _epochs)\n",
    "\n",
    "            epoch_loss = []\n",
    "            epoch_train_em = []\n",
    "            epoch_time = time.time()\n",
    "\n",
    "            for iter in range(int(len(train_P)/BATCH_SIZE)):\n",
    "    #         for iter in range(2):\n",
    "\n",
    "                batch_time = time.time()\n",
    "\n",
    "                # Sample batch and train on it\n",
    "                sample_index = np.random.randint(0, len(train_P), _macros['batch_size'])\n",
    "            \n",
    "#                 grad_old = sum([x.grad.sum().item() for x in params])\n",
    "\n",
    "                y_cap_start, y_cap_end, loss = train(\n",
    "                    para_batch = torch.tensor(train_P[sample_index], dtype=torch.long, device=device),\n",
    "                    ques_batch = torch.tensor(train_Q[sample_index], dtype=torch.long, device=device),\n",
    "                    answer_start_batch = torch.tensor(train_Y_start[sample_index], dtype=torch.float, device=device).view( _macros['batch_size'], 1, _macros['para_len']),\n",
    "                    answer_end_batch = torch.tensor(train_Y_end[sample_index], dtype=torch.float, device=device).view(_macros['batch_size'], 1, _macros['para_len']),\n",
    "                    ques_model = ques_model,\n",
    "                    para_model = para_model,\n",
    "                    mlstm_model = mlstm_model,\n",
    "                    pointer_decoder_model = pointer_decoder_model,\n",
    "                    optimizer = optimizer, \n",
    "                    loss_fn= loss_fn,\n",
    "                    macros=_macros,\n",
    "                    debug=_macros['debug']\n",
    "                )\n",
    "\n",
    "                if _train_eval: \n",
    "\n",
    "                    # Calculate train accuracy for this minibatch\n",
    "                    metrics = eval(\n",
    "                        y=(torch.tensor(train_Y_start[sample_index], dtype=torch.long, device=device).view( -1, _macros['para_len']),\n",
    "                            torch.tensor(train_Y_end[sample_index], dtype=torch.long, device=device).view(-1, _macros['para_len'])),\n",
    "                        y_cap=[y_cap_start.squeeze(), y_cap_end.squeeze()])\n",
    "\n",
    "                    epoch_train_em.append(metrics['em'])\n",
    "    \n",
    "                epoch_loss.append(loss.item())\n",
    "    \n",
    "#                 grad_new = sum([x.grad.sum().item() for x in params])\n",
    "\n",
    "                print(\"Batch:\\t%d\" % iter,\"/%d\\t: \" % (len(train_P)/_macros['batch_size']),\n",
    "                      str(\"%s\" % (time.time() - batch_time))[:8], \n",
    "                      str(\"\\t\\b%s\" % (time.time() - epoch_time))[:10], \n",
    "                      \"\\tl:%f\" % loss.item(),\n",
    "                      \"\\tem:%f\" % epoch_train_em[-1] if _train_eval else \"\")\n",
    "#                      \"\\t\\b\\b%s\" % grad_new - grad_old)\n",
    "#                      end=None if iter+1 == int(len(train_P)/BATCH_SIZE) else \"\\r\")\n",
    "\n",
    "            train_losses.append(epoch_loss)\n",
    "        \n",
    "            if _train_eval: train_em.append(epoch_train_em)\n",
    "#             if np.mean(epoch_train_em) > best_test_em:\n",
    "#                 found_best_test_em = True\n",
    "#                 best_test_em = np.mean(epoch_train_em)\n",
    "                \n",
    "            if _test_eval and epoch % _test_eval == 0:\n",
    "\n",
    "                y_cap_start, y_cap_end, test_loss = predict(\n",
    "                    para_batch = torch.tensor(test_P, dtype=torch.long, device=device),\n",
    "                    ques_batch = torch.tensor(test_Q, dtype=torch.long, device=device),\n",
    "                    ques_model = ques_model,\n",
    "                    para_model = para_model,\n",
    "                    mlstm_model = mlstm_model,\n",
    "                    pointer_decoder_model = pointer_decoder_model,\n",
    "                    macros = _macros,\n",
    "                    loss_fn= loss_fn,\n",
    "                    debug = _macros['debug']\n",
    "                )\n",
    "                metrics = eval(\n",
    "                    y=(torch.tensor(test_Y_start, dtype=torch.long, device=device).view( -1, _macros['para_len']),\n",
    "                        torch.tensor(test_Y_end, dtype=torch.long, device=device).view(-1, _macros['para_len'])),\n",
    "                    y_cap=[y_cap_start.squeeze(), y_cap_end.squeeze()])\n",
    "\n",
    "                test_losses.append(test_loss)\n",
    "                test_em.append(metrics['em'])\n",
    "                \n",
    "                # Check if we outperformed the best one.\n",
    "                if metrics['em'] > best_test_em:\n",
    "                    \n",
    "                    # Set flag\n",
    "                    found_best_test_em = True\n",
    "                    \n",
    "                    # Update value\n",
    "                    best_test_em = metrics['em']   \n",
    "                \n",
    "            # Saving logic\n",
    "            if _save == 0:\n",
    "                pass\n",
    "            elif ( _save>0 and epoch % _save == 0) or \\\n",
    "            ( _save == -1 and found_best_test_em ):\n",
    "                models = { 'ques_model': ques_model,\n",
    "                           'para_model': para_model,\n",
    "                           'mlstm_model':  mlstm_model,\n",
    "                           'pointer_decoder_model': pointer_decoder_model\n",
    "                         }\n",
    "                \n",
    "                save_model(macros['save_model_loc'], models,\n",
    "                          epochs=epoch,\n",
    "                           optimizer=optimizer)\n",
    "                \n",
    "                print(\"Saving new model on epoch %d\" % epoch)\n",
    "            \n",
    "            # Reset flags\n",
    "            found_best_test_em = False\n",
    "            \n",
    "            # At the end of every epoch, do print the average epoch loss, and other stat\n",
    "            print(\"\\nEpoch performance: \",\n",
    "                  \"%ssec\" % str(time.time() - epoch_time)[:6],\n",
    "                  \"Trl:%f\" % np.mean(epoch_loss, axis=0),\n",
    "                  \"\\tTrem:%f\" % np.mean(epoch_train_em) if _train_eval and epoch % _train_eval == 0 else \"\",\n",
    "                  \"\\tTeem:%f\\n\" % test_em[-1] if _test_eval and epoch % _test_eval == 0 else \"\\n\")\n",
    "\n",
    "#         return train_losses, train_em, test_losses, test_em\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        \n",
    "        # someone called a ctrl+c on it. Let' return the things computed so far atlest.\n",
    "        print(\"Found keyboard interrupt. Stopping training loop\")\n",
    "        \n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    finally:       \n",
    "        return train_losses, train_em, test_losses, test_em\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    Saving said models.\n",
    "    TODO\n",
    "\"\"\"\n",
    "# ques_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(loss, _label=\"Some label\", _only_epoch=True):\n",
    "    \"\"\"\n",
    "        Fn to visualize loss.\n",
    "        Expects either\n",
    "            - [int, int] for epoch level stuff\n",
    "            - [ [int, int], [int, int] ] for batch level data. \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [15, 8] \n",
    "    \n",
    "    # Detect input format\n",
    "    if type(loss[0]) in [int, float, long]:\n",
    "        \n",
    "#         print(\"here\")\n",
    "        \n",
    "        plt.plot(loss)\n",
    "        plt.ylabel(_label)\n",
    "        plt.show()\n",
    "        \n",
    "    elif type(loss[0]) == list:\n",
    "        \n",
    "        if _only_epoch:\n",
    "            loss = [ sum(x) for x in loss ]\n",
    "            \n",
    "        else:\n",
    "            loss = [ y for x in loss for y in x ]\n",
    "            \n",
    "        plt.plot(loss)\n",
    "        plt.ylabel(_label)\n",
    "        plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrator\n",
    "\n",
    "One cell which instantiates and runs everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Q:  (466, 30)\n",
      "Train P:  (466, 200)\n",
      "Train Y:  (466, 200)\n",
      "Test Q:  (119, 30)\n",
      "Test P:  (119, 200)\n",
      "Test Y:  (119, 200)\n",
      "Crop_train:  7\n",
      "Crop_test:  0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Cell which pulls everything together.\n",
    "\n",
    "    > init models\n",
    "    > get data prepared\n",
    "    > pass models and data to training loop\n",
    "    > gets trained models and loss\n",
    "    > saves models\n",
    "    > visualizes loss?\n",
    "\n",
    "No other function but this one ever sees global macros!\n",
    "\"\"\"\n",
    "macros = {\n",
    "    \"ques_len\": QUES_LEN,\n",
    "    \"hidden_dim\": HIDDEN_DIM, \n",
    "    \"vocab_size\": VOCAB_SIZE, \n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"para_len\": PARA_LEN,\n",
    "    \"embedding_dim\": EMBEDDING_DIM,\n",
    "    \"lr\": LR,\n",
    "    \"debug\":DEBUG,\n",
    "    \"save_model_loc\": MODEL_LOC\n",
    "#     \"device\": device\n",
    "} \n",
    "\n",
    "data = {'train':{}, 'test':{}}\n",
    "data['train']['P'], data['train']['Q'], data['train']['Ys'], data['train']['Ye'], \\\n",
    "data['test']['P'], data['test']['Q'], data['test']['Ys'], data['test']['Ye'], vectors = \\\n",
    "    prepare_data(DATA_LOC, macros, crop=CROP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate modelshttp://localhost:8888/notebooks/model.ipynb#\n",
    "ques_model = Encoder(QUES_LEN, macros, vectors, device).cuda(device)\n",
    "para_model = Encoder(PARA_LEN, macros, vectors, device).cuda(device)\n",
    "mlstm_model = MatchLSTMEncoder(macros, device).cuda(device)\n",
    "pointer_decoder_model = PointerDecoder(macros, device).cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 / 300\n",
      "Batch:\t0 /9\t:  1.294736 1.294751 \tl:10.583466 \tem:0.000000\n",
      "Batch:\t1 /9\t:  1.028904 2.325188 \tl:9.414362 \tem:0.000000\n",
      "Batch:\t2 /9\t:  1.090769 3.416692 \tl:8.668116 \tem:0.000000\n",
      "Batch:\t3 /9\t:  1.211329 4.629376 \tl:8.522520 \tem:0.000000\n",
      "Batch:\t4 /9\t:  1.113830 5.744143 \tl:9.525246 \tem:0.000000\n",
      "Batch:\t5 /9\t:  1.299049 7.044671 \tl:8.589943 \tem:0.000000\n",
      "Batch:\t6 /9\t:  1.326445 8.371842 \tl:7.914226 \tem:0.000000\n",
      "Batch:\t7 /9\t:  1.277424 9.650438 \tl:8.140624 \tem:0.000000\n",
      "Batch:\t8 /9\t:  1.316005 10.96778 \tl:8.158880 \tem:0.000000\n",
      "\n",
      "Epoch performance:  11.161sec Trl:8.835265 \tTrem:0.000000 \tTeem:0.000000\n",
      "\n",
      "Epoch:  1 / 300\n",
      "Batch:\t0 /9\t:  1.136246 1.136262 \tl:8.112770 \tem:0.000000\n",
      "Batch:\t1 /9\t:  1.100538 2.237080 \tl:7.979981 \tem:0.000000\n",
      "Batch:\t2 /9\t:  1.233996 3.471861 \tl:7.328404 \tem:0.000000\n",
      "Batch:\t3 /9\t:  1.191274 4.663412 \tl:7.801500 \tem:0.000000\n",
      "Batch:\t4 /9\t:  1.035587 5.700534 \tl:7.394086 \tem:0.000000\n",
      "Batch:\t5 /9\t:  1.245047 6.946410 \tl:6.660672 \tem:0.000000\n",
      "Batch:\t6 /9\t:  1.249408 8.196768 \tl:7.456442 \tem:0.000000\n",
      "Batch:\t7 /9\t:  1.219342 9.416821 \tl:7.322899 \tem:0.000000\n",
      "Batch:\t8 /9\t:  1.106474 10.52448 \tl:7.007781 \tem:0.000000\n",
      "\n",
      "Epoch performance:  10.741sec Trl:7.451615 \tTrem:0.000000 \tTeem:0.000000\n",
      "\n",
      "Epoch:  2 / 300\n",
      "Batch:\t0 /9\t:  1.227996 1.228020 \tl:7.287562 \tem:0.000000\n",
      "Batch:\t1 /9\t:  1.079123 2.308547 \tl:6.865221 \tem:0.000000\n",
      "Batch:\t2 /9\t:  1.244499 3.554269 \tl:6.819185 \tem:0.040000\n",
      "Batch:\t3 /9\t:  1.127516 4.682298 \tl:6.219960 \tem:0.000000\n",
      "Batch:\t4 /9\t:  1.228143 5.920060 \tl:6.829328 \tem:0.000000\n",
      "Batch:\t5 /9\t:  1.085129 7.006317 \tl:7.301320 \tem:0.000000\n",
      "Batch:\t6 /9\t:  1.160115 8.168711 \tl:6.619207 \tem:0.000000\n",
      "Batch:\t7 /9\t:  1.420808 9.590559 \tl:6.396840 \tem:0.000000\n",
      "Batch:\t8 /9\t:  1.130523 10.72231 \tl:6.205810 \tem:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/priyansh/virtualenvironment/pwc-reg-m/local/lib/python2.7/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type PointerDecoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/data/priyansh/virtualenvironment/pwc-reg-m/local/lib/python2.7/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/data/priyansh/virtualenvironment/pwc-reg-m/local/lib/python2.7/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type MatchLSTMEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new model on epoch 2\n",
      "\n",
      "Epoch performance:  12.056sec Trl:6.727159 \tTrem:0.004444 \tTeem:0.016807\n",
      "\n",
      "Epoch:  3 / 300\n",
      "Batch:\t0 /9\t:  1.228941 1.228963 \tl:5.863198 \tem:0.020000\n",
      "Batch:\t1 /9\t:  1.114305 2.343926 \tl:6.518927 \tem:0.000000\n",
      "Batch:\t2 /9\t:  1.115854 3.460439 \tl:5.939472 \tem:0.000000\n",
      "Batch:\t3 /9\t:  1.204533 4.665256 \tl:6.124633 \tem:0.000000\n",
      "Batch:\t4 /9\t:  1.261218 5.926715 \tl:5.998361 \tem:0.000000\n",
      "Batch:\t5 /9\t:  1.282689 7.211236 \tl:6.222171 \tem:0.000000\n",
      "Batch:\t6 /9\t:  1.190489 8.402601 \tl:5.791663 \tem:0.000000\n",
      "Batch:\t7 /9\t:  1.330023 9.733293 \tl:5.914903 \tem:0.000000\n",
      "Batch:\t8 /9\t:  1.219648 10.95370 \tl:5.762264 \tem:0.000000\n",
      "\n",
      "Epoch performance:  11.117sec Trl:6.015066 \tTrem:0.002222 \tTeem:0.000000\n",
      "\n",
      "Epoch:  4 / 300\n",
      "Batch:\t0 /9\t:  1.182655 1.182682 \tl:5.551534 \tem:0.000000\n",
      "Batch:\t1 /9\t:  1.115649 2.300460 \tl:5.489725 \tem:0.000000\n",
      "Batch:\t2 /9\t:  1.212069 3.513378 \tl:5.357818 \tem:0.000000\n",
      "Batch:\t3 /9\t:  1.139220 4.654295 \tl:4.837436 \tem:0.000000\n",
      "Batch:\t4 /9\t:  1.213154 5.868564 \tl:4.677864 \tem:0.020000\n",
      "Batch:\t5 /9\t:  1.142977 7.012655 \tl:5.669066 \tem:0.000000\n",
      "Batch:\t6 /9\t:  1.117191 8.130832 \tl:4.059865 \tem:0.020000\n",
      "Batch:\t7 /9\t:  1.211024 9.342712 \tl:4.407181 \tem:0.000000\n",
      "Batch:\t8 /9\t:  1.158107 10.50178 \tl:4.912185 \tem:0.020000\n",
      "Saving new model on epoch 4\n",
      "\n",
      "Epoch performance:  11.522sec Trl:4.995852 \tTrem:0.006667 \tTeem:0.016807\n",
      "\n",
      "Epoch:  5 / 300\n",
      "Batch:\t0 /9\t:  1.038209 1.038228 \tl:4.125364 \tem:0.000000\n",
      "Batch:\t1 /9\t:  1.215693 2.254195 \tl:4.240085 \tem:0.000000\n",
      "Batch:\t2 /9\t:  1.259359 3.514411 \tl:4.137084 \tem:0.000000\n",
      "Batch:\t3 /9\t:  1.216983 4.732321 \tl:4.144815 \tem:0.000000\n",
      "Batch:\t4 /9\t:  1.108361 5.841706 \tl:3.786431 \tem:0.000000\n",
      "Batch:\t5 /9\t:  1.140868 6.983307 \tl:4.156988 \tem:0.000000\n",
      "Batch:\t6 /9\t:  1.219344 8.203315 \tl:3.619961 \tem:0.000000\n",
      "Batch:\t7 /9\t:  1.187135 9.404873 \tl:3.419767 \tem:0.000000\n",
      "Batch:\t8 /9\t:  1.265650 10.67110 \tl:4.043047 \tem:0.020000\n",
      "\n",
      "Epoch performance:  10.860sec Trl:3.963727 \tTrem:0.002222 \tTeem:0.016807\n",
      "\n",
      "Epoch:  6 / 300\n",
      "Batch:\t0 /9\t:  1.241793 1.241811 \tl:3.971370 \tem:0.020000\n",
      "Batch:\t1 /9\t:  1.154379 2.397185 \tl:3.532715 \tem:0.000000\n",
      "Batch:\t2 /9\t:  1.105208 3.502779 \tl:3.336041 \tem:0.000000\n",
      "Batch:\t3 /9\t:  1.113335 4.617355 \tl:3.750000 \tem:0.000000\n",
      "Batch:\t4 /9\t:  1.258018 5.875890 \tl:3.809489 \tem:0.020000\n",
      "Batch:\t5 /9\t:  1.093716 6.970058 \tl:3.221941 \tem:0.040000\n",
      "Batch:\t6 /9\t:  1.198873 8.169596 \tl:3.517370 \tem:0.000000\n",
      "Batch:\t7 /9\t:  1.223503 9.393532 \tl:3.389116 \tem:0.000000\n",
      "Batch:\t8 /9\t:  1.283397 10.67757 \tl:3.199608 \tem:0.000000\n",
      "Saving new model on epoch 6\n",
      "\n",
      "Epoch performance:  11.960sec Trl:3.525295 \tTrem:0.008889 \tTeem:0.016807\n",
      "\n",
      "Epoch:  7 / 300\n",
      "Batch:\t0 /9\t:  1.170316 1.170335 \tl:3.289530 \tem:0.080000\n",
      "Batch:\t1 /9\t:  1.257032 2.428378 \tl:3.308245 \tem:0.000000\n",
      "Batch:\t2 /9\t:  1.126596 3.555222 \tl:2.788931 \tem:0.020000\n",
      "Batch:\t3 /9\t:  1.255383 4.811141 \tl:2.917871 \tem:0.060000\n",
      "Batch:\t4 /9\t:  1.096497 5.908699 \tl:3.544142 \tem:0.020000\n",
      "Batch:\t5 /9\t:  1.225484 7.134798 \tl:2.669762 \tem:0.080000\n",
      "Batch:\t6 /9\t:  1.234961 8.370158 \tl:2.969719 \tem:0.060000\n",
      "Batch:\t7 /9\t:  1.059348 9.430485 \tl:2.914409 \tem:0.100000\n",
      "Batch:\t8 /9\t:  1.141779 10.57283 \tl:2.754514 \tem:0.020000\n",
      "Saving new model on epoch 7\n",
      "\n",
      "Epoch performance:  11.674sec Trl:3.017458 \tTrem:0.048889 \tTeem:0.033613\n",
      "\n",
      "Epoch:  8 / 300\n",
      "Batch:\t0 /9\t:  1.064027 1.064038 \tl:3.303928 \tem:0.080000\n",
      "Batch:\t1 /9\t:  1.215059 2.279301 \tl:2.482571 \tem:0.100000\n",
      "Batch:\t2 /9\t:  1.163026 3.444184 \tl:2.812513 \tem:0.100000\n",
      "Batch:\t3 /9\t:  1.097944 4.542647 \tl:2.499145 \tem:0.180000\n",
      "Batch:\t4 /9\t:  1.253157 5.796687 \tl:2.845545 \tem:0.080000\n",
      "Batch:\t5 /9\t:  1.196714 6.993935 \tl:3.467854 \tem:0.160000\n",
      "Batch:\t6 /9\t:  1.223079 8.217569 \tl:2.644260 \tem:0.200000\n",
      "Batch:\t7 /9\t:  1.111799 9.329689 \tl:2.492959 \tem:0.140000\n",
      "Batch:\t8 /9\t:  1.293267 10.62408 \tl:2.177128 \tem:0.260000\n",
      "Saving new model on epoch 8\n",
      "\n",
      "Epoch performance:  11.604sec Trl:2.747323 \tTrem:0.144444 \tTeem:0.058824\n",
      "\n",
      "Epoch:  9 / 300\n",
      "Batch:\t0 /9\t:  1.113835 1.113853 \tl:2.294315 \tem:0.200000\n",
      "Batch:\t1 /9\t:  1.119982 2.234098 \tl:2.050751 \tem:0.120000\n",
      "Batch:\t2 /9\t:  1.110893 3.345718 \tl:2.511683 \tem:0.340000\n",
      "Batch:\t3 /9\t:  1.138546 4.484926 \tl:1.972519 \tem:0.320000\n",
      "Batch:\t4 /9\t:  1.143275 5.628786 \tl:1.800097 \tem:0.360000\n",
      "Batch:\t5 /9\t:  1.255688 6.885545 \tl:2.132018 \tem:0.300000\n",
      "Batch:\t6 /9\t:  1.208997 8.094757 \tl:1.768562 \tem:0.500000\n",
      "Batch:\t7 /9\t:  1.177679 9.273506 \tl:2.019816 \tem:0.380000\n",
      "Batch:\t8 /9\t:  1.300295 10.57432 \tl:1.843562 \tem:0.540000\n",
      "Saving new model on epoch 9\n",
      "\n",
      "Epoch performance:  12.032sec Trl:2.043702 \tTrem:0.340000 \tTeem:0.075630\n",
      "\n",
      "Epoch:  10 / 300\n",
      "Batch:\t0 /9\t:  1.297045 1.297070 \tl:1.667047 \tem:0.540000\n",
      "Batch:\t1 /9\t:  1.138828 2.436212 \tl:1.416665 \tem:0.540000\n",
      "Batch:\t2 /9\t:  1.123955 3.560684 \tl:1.670660 \tem:0.600000\n",
      "Batch:\t3 /9\t:  1.123543 4.685314 \tl:1.722521 \tem:0.520000\n",
      "Batch:\t4 /9\t:  1.156311 5.842155 \tl:1.389904 \tem:0.560000\n",
      "Batch:\t5 /9\t:  1.151907 6.994718 \tl:1.335605 \tem:0.640000\n",
      "Batch:\t6 /9\t:  1.285003 8.280404 \tl:1.022390 \tem:0.680000\n",
      "Batch:\t7 /9\t:  1.242448 9.523514 \tl:1.285106 \tem:0.720000\n",
      "Batch:\t8 /9\t:  1.199059 10.72356 \tl:0.998260 \tem:0.680000\n",
      "Saving new model on epoch 10\n",
      "\n",
      "Epoch performance:  11.737sec Trl:1.389795 \tTrem:0.608889 \tTeem:0.084034\n",
      "\n",
      "Epoch:  11 / 300\n",
      "Batch:\t0 /9\t:  1.233552 1.233569 \tl:1.201399 \tem:0.580000\n",
      "Batch:\t1 /9\t:  1.147849 2.382553 \tl:1.180743 \tem:0.640000\n",
      "Batch:\t2 /9\t:  1.154535 3.537645 \tl:1.676206 \tem:0.700000\n",
      "Batch:\t3 /9\t:  1.134140 4.672826 \tl:0.634761 \tem:0.820000\n",
      "Batch:\t4 /9\t:  1.158801 5.833080 \tl:1.085299 \tem:0.700000\n",
      "Batch:\t5 /9\t:  1.177157 7.011429 \tl:0.827525 \tem:0.800000\n",
      "Batch:\t6 /9\t:  1.152884 8.165343 \tl:0.895803 \tem:0.740000\n",
      "Batch:\t7 /9\t:  1.359862 9.526373 \tl:0.976774 \tem:0.760000\n",
      "Batch:\t8 /9\t:  1.268418 10.79601 \tl:0.890497 \tem:0.760000\n",
      "Saving new model on epoch 11\n",
      "\n",
      "Epoch performance:  11.919sec Trl:1.041001 \tTrem:0.722222 \tTeem:0.092437\n",
      "\n",
      "Epoch:  12 / 300\n",
      "Batch:\t0 /9\t:  1.322836 1.322855 \tl:1.075382 \tem:0.740000\n",
      "Batch:\t1 /9\t:  1.327700 2.651180 \tl:0.784673 \tem:0.840000\n",
      "Batch:\t2 /9\t:  1.340989 3.993026 \tl:0.766506 \tem:0.820000\n",
      "Batch:\t3 /9\t:  1.218166 5.212173 \tl:0.914566 \tem:0.860000\n",
      "Batch:\t4 /9\t:  1.539750 6.753026 \tl:0.516560 \tem:0.900000\n",
      "Batch:\t5 /9\t:  1.443053 8.196331 \tl:0.844877 \tem:0.780000\n",
      "Batch:\t6 /9\t:  1.425510 9.623632 \tl:0.864636 \tem:0.820000\n",
      "Batch:\t7 /9\t:  1.234216 10.85842 \tl:0.431928 \tem:0.920000\n",
      "Batch:\t8 /9\t:  1.196931 12.05583 \tl:0.722592 \tem:0.820000\n",
      "Saving new model on epoch 12\n",
      "\n",
      "Epoch performance:  12.996sec Trl:0.769080 \tTrem:0.833333 \tTeem:0.092437\n",
      "\n",
      "Epoch:  13 / 300\n",
      "Batch:\t0 /9\t:  1.231785 1.231806 \tl:0.449044 \tem:0.860000\n",
      "Batch:\t1 /9\t:  1.140156 2.372881 \tl:1.009654 \tem:0.840000\n",
      "Batch:\t2 /9\t:  1.142930 3.516458 \tl:0.410683 \tem:0.880000\n",
      "Batch:\t3 /9\t:  1.135720 4.652866 \tl:0.414663 \tem:0.920000\n",
      "Batch:\t4 /9\t:  1.129086 5.782702 \tl:0.966952 \tem:0.740000\n",
      "Batch:\t5 /9\t:  1.056396 6.839529 \tl:0.532360 \tem:0.860000\n",
      "Batch:\t6 /9\t:  1.076050 7.918356 \tl:0.243721 \tem:0.980000\n",
      "Batch:\t7 /9\t:  1.157322 9.075984 \tl:0.649475 \tem:0.900000\n",
      "Batch:\t8 /9\t:  1.355602 10.43263 \tl:0.325840 \tem:0.900000\n",
      "Saving new model on epoch 13\n",
      "\n",
      "Epoch performance:  11.417sec Trl:0.555821 \tTrem:0.875556 \tTeem:0.084034\n",
      "\n",
      "Epoch:  14 / 300\n",
      "Batch:\t0 /9\t:  1.260494 1.260524 \tl:0.575668 \tem:0.860000\n",
      "Batch:\t1 /9\t:  1.247134 2.508846 \tl:0.545672 \tem:0.880000\n",
      "Batch:\t2 /9\t:  1.214782 3.724143 \tl:0.623279 \tem:0.860000\n",
      "Batch:\t3 /9\t:  1.296418 5.021150 \tl:0.320337 \tem:0.900000\n",
      "Batch:\t4 /9\t:  1.241471 6.263595 \tl:0.280039 \tem:0.920000\n",
      "Batch:\t5 /9\t:  1.148021 7.413091 \tl:0.219834 \tem:0.980000\n",
      "Batch:\t6 /9\t:  1.207870 8.621530 \tl:0.243031 \tem:0.920000\n",
      "Batch:\t7 /9\t:  1.408088 10.03051 \tl:0.144831 \tem:1.000000\n",
      "Batch:\t8 /9\t:  1.405018 11.43692 \tl:0.425709 \tem:0.920000\n",
      "Saving new model on epoch 14\n",
      "\n",
      "Epoch performance:  12.512sec Trl:0.375378 \tTrem:0.915556 \tTeem:0.109244\n",
      "\n",
      "Epoch:  15 / 300\n",
      "Batch:\t0 /9\t:  1.285798 1.285816 \tl:0.359002 \tem:0.940000\n",
      "Batch:\t1 /9\t:  1.524802 2.811596 \tl:0.134616 \tem:0.980000\n",
      "Batch:\t2 /9\t:  1.289231 4.101030 \tl:0.133388 \tem:0.960000\n",
      "Batch:\t3 /9\t:  1.555957 5.657835 \tl:0.092484 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.421821 7.080863 \tl:0.154731 \tem:0.980000\n",
      "Batch:\t5 /9\t:  1.497552 8.578923 \tl:0.383046 \tem:0.880000\n",
      "Batch:\t6 /9\t:  1.530596 10.11001 \tl:0.099993 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.085341 11.19586 \tl:0.452833 \tem:0.940000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:\t8 /9\t:  1.280818 12.47774 \tl:0.112524 \tem:0.960000\n",
      "Saving new model on epoch 15\n",
      "\n",
      "Epoch performance:  13.477sec Trl:0.213624 \tTrem:0.960000 \tTeem:0.092437\n",
      "\n",
      "Epoch:  16 / 300\n",
      "Batch:\t0 /9\t:  1.265691 1.265707 \tl:0.127515 \tem:0.960000\n",
      "Batch:\t1 /9\t:  1.210262 2.476609 \tl:0.040389 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.166602 3.644490 \tl:0.334884 \tem:0.960000\n",
      "Batch:\t3 /9\t:  1.251402 4.897030 \tl:0.271078 \tem:0.960000\n",
      "Batch:\t4 /9\t:  1.160839 6.058702 \tl:0.042468 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.276289 7.335566 \tl:0.201591 \tem:0.940000\n",
      "Batch:\t6 /9\t:  1.233432 8.569527 \tl:0.172329 \tem:0.940000\n",
      "Batch:\t7 /9\t:  1.264972 9.835439 \tl:0.111396 \tem:1.000000\n",
      "Batch:\t8 /9\t:  1.137330 10.97304 \tl:0.205022 \tem:0.940000\n",
      "Saving new model on epoch 16\n",
      "\n",
      "Epoch performance:  11.933sec Trl:0.167408 \tTrem:0.966667 \tTeem:0.092437\n",
      "\n",
      "Epoch:  17 / 300\n",
      "Batch:\t0 /9\t:  1.335903 1.335929 \tl:0.149267 \tem:0.940000\n",
      "Batch:\t1 /9\t:  1.344568 2.681071 \tl:0.214567 \tem:0.960000\n",
      "Batch:\t2 /9\t:  1.471757 4.153720 \tl:0.030063 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.550488 5.705515 \tl:0.090697 \tem:0.960000\n",
      "Batch:\t4 /9\t:  1.511612 7.218096 \tl:0.195846 \tem:0.980000\n",
      "Batch:\t5 /9\t:  1.492759 8.711827 \tl:0.041928 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.188125 9.900968 \tl:0.038668 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.174305 11.07557 \tl:0.175916 \tem:0.940000\n",
      "Batch:\t8 /9\t:  1.267673 12.34443 \tl:0.071067 \tem:0.980000\n",
      "Saving new model on epoch 17\n",
      "\n",
      "Epoch performance:  13.358sec Trl:0.112002 \tTrem:0.973333 \tTeem:0.075630\n",
      "\n",
      "Epoch:  18 / 300\n",
      "Batch:\t0 /9\t:  1.254242 1.254266 \tl:0.095756 \tem:0.980000\n",
      "Batch:\t1 /9\t:  1.307322 2.562177 \tl:0.030587 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.243849 3.807297 \tl:0.088138 \tem:0.980000\n",
      "Batch:\t3 /9\t:  1.264019 5.071846 \tl:0.045241 \tem:0.980000\n",
      "Batch:\t4 /9\t:  1.354056 6.426762 \tl:0.037454 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.167277 7.595057 \tl:0.024352 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.259486 8.855885 \tl:0.030765 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.227926 10.08502 \tl:0.032970 \tem:1.000000\n",
      "Batch:\t8 /9\t:  1.159058 11.24490 \tl:0.021087 \tem:1.000000\n",
      "Saving new model on epoch 18\n",
      "\n",
      "Epoch performance:  12.259sec Trl:0.045150 \tTrem:0.993333 \tTeem:0.092437\n",
      "\n",
      "Epoch:  19 / 300\n",
      "Batch:\t0 /9\t:  1.353770 1.353786 \tl:0.110273 \tem:0.980000\n",
      "Batch:\t1 /9\t:  1.070542 2.424826 \tl:0.039399 \tem:0.980000\n",
      "Batch:\t2 /9\t:  1.074784 3.500084 \tl:0.034137 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.102642 4.603662 \tl:0.020230 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.334637 5.940495 \tl:0.010026 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.139709 7.080832 \tl:0.018219 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.152704 8.234570 \tl:0.023019 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.226339 9.462240 \tl:0.010125 \tem:1.000000\n",
      "Batch:\t8 /9\t:  1.219981 10.68333 \tl:0.130520 \tem:0.960000\n",
      "\n",
      "Epoch performance:  10.900sec Trl:0.043994 \tTrem:0.991111 \tTeem:0.117647\n",
      "\n",
      "Epoch:  20 / 300\n",
      "Batch:\t0 /9\t:  1.338973 1.338994 \tl:0.065983 \tem:0.980000\n",
      "Batch:\t1 /9\t:  1.231133 2.571279 \tl:0.012878 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.296073 3.868894 \tl:0.015795 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.276642 5.146623 \tl:0.012733 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.347975 6.495940 \tl:0.013391 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.357980 7.854623 \tl:0.009479 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.227866 9.083472 \tl:0.026318 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.157244 10.24175 \tl:0.102849 \tem:0.980000\n",
      "Batch:\t8 /9\t:  1.120016 11.36298 \tl:0.016569 \tem:1.000000\n",
      "Saving new model on epoch 20\n",
      "\n",
      "Epoch performance:  12.341sec Trl:0.030666 \tTrem:0.995556 \tTeem:0.109244\n",
      "\n",
      "Epoch:  21 / 300\n",
      "Batch:\t0 /9\t:  1.233980 1.234007 \tl:0.011888 \tem:1.000000\n",
      "Batch:\t1 /9\t:  1.279577 2.515092 \tl:0.007836 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.154334 3.671067 \tl:0.039286 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.133455 4.805007 \tl:0.111958 \tem:0.980000\n",
      "Batch:\t4 /9\t:  1.175793 5.981381 \tl:0.008845 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.251684 7.233338 \tl:0.011676 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.069684 8.303453 \tl:0.008750 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.237668 9.542282 \tl:0.174549 \tem:0.980000\n",
      "Batch:\t8 /9\t:  1.270973 10.81462 \tl:0.008263 \tem:1.000000\n",
      "\n",
      "Epoch performance:  11.014sec Trl:0.042561 \tTrem:0.995556 \tTeem:0.092437\n",
      "\n",
      "Epoch:  22 / 300\n",
      "Batch:\t0 /9\t:  1.186281 1.186299 \tl:0.054200 \tem:0.980000\n",
      "Batch:\t1 /9\t:  1.161134 2.348505 \tl:0.009329 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.164651 3.514413 \tl:0.009082 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.251281 4.766853 \tl:0.015588 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.228546 5.995692 \tl:0.015021 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.364504 7.361476 \tl:0.009725 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.335285 8.698148 \tl:0.010506 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.523452 10.22236 \tl:0.020839 \tem:1.000000\n",
      "Batch:\t8 /9\t:  1.430364 11.65355 \tl:0.009810 \tem:1.000000\n",
      "Saving new model on epoch 22\n",
      "\n",
      "Epoch performance:  12.640sec Trl:0.017122 \tTrem:0.997778 \tTeem:0.100840\n",
      "\n",
      "Epoch:  23 / 300\n",
      "Batch:\t0 /9\t:  1.271265 1.271290 \tl:0.009776 \tem:1.000000\n",
      "Batch:\t1 /9\t:  1.172278 2.444782 \tl:0.019504 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.215393 3.661117 \tl:0.010317 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.234354 4.896237 \tl:0.006825 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.570684 6.467491 \tl:0.012649 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.321795 7.790208 \tl:0.007770 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.259791 9.051177 \tl:0.006760 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.157171 10.20885 \tl:0.079827 \tem:0.980000\n",
      "Batch:\t8 /9\t:  1.257034 11.46638 \tl:0.006057 \tem:1.000000\n",
      "\n",
      "Epoch performance:  11.666sec Trl:0.017721 \tTrem:0.997778 \tTeem:0.100840\n",
      "\n",
      "Epoch:  24 / 300\n",
      "Batch:\t0 /9\t:  1.266014 1.266030 \tl:0.010242 \tem:1.000000\n",
      "Batch:\t1 /9\t:  1.145184 2.411828 \tl:0.104273 \tem:0.960000\n",
      "Batch:\t2 /9\t:  1.262892 3.675768 \tl:0.005738 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.266887 4.943202 \tl:0.005410 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.215287 6.159285 \tl:0.018015 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.261485 7.421388 \tl:0.009103 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.138143 8.560066 \tl:0.009183 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.165733 9.726999 \tl:0.011305 \tem:1.000000\n",
      "Batch:\t8 /9\t:  1.270566 10.99855 \tl:0.015757 \tem:1.000000\n",
      "\n",
      "Epoch performance:  11.191sec Trl:0.021003 \tTrem:0.995556 \tTeem:0.134454\n",
      "\n",
      "Epoch:  25 / 300\n",
      "Batch:\t0 /9\t:  1.114344 1.114358 \tl:0.037039 \tem:1.000000\n",
      "Batch:\t1 /9\t:  1.155318 2.270133 \tl:0.066048 \tem:0.960000\n",
      "Batch:\t2 /9\t:  1.144958 3.415991 \tl:0.008634 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.160856 4.577994 \tl:0.009295 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.231981 5.810647 \tl:0.011404 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.345292 7.156994 \tl:0.013212 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.120733 8.278388 \tl:0.010321 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.061948 9.341147 \tl:0.093534 \tem:0.980000\n",
      "Batch:\t8 /9\t:  1.113569 10.45491 \tl:0.016913 \tem:1.000000\n",
      "\n",
      "Epoch performance:  10.658sec Trl:0.029600 \tTrem:0.993333 \tTeem:0.109244\n",
      "\n",
      "Epoch:  26 / 300\n",
      "Batch:\t0 /9\t:  1.308488 1.308507 \tl:0.012349 \tem:1.000000\n",
      "Batch:\t1 /9\t:  1.213540 2.522420 \tl:0.004968 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.070292 3.592957 \tl:0.087126 \tem:0.980000\n",
      "Batch:\t3 /9\t:  1.068040 4.661650 \tl:0.065470 \tem:0.960000\n",
      "Batch:\t4 /9\t:  1.231332 5.894171 \tl:0.435654 \tem:0.940000\n",
      "Batch:\t5 /9\t:  1.102463 6.997228 \tl:0.013899 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.225333 8.222784 \tl:0.022008 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.154015 9.377209 \tl:0.525800 \tem:0.920000\n",
      "Batch:\t8 /9\t:  1.286897 10.66513 \tl:0.736439 \tem:0.860000\n",
      "\n",
      "Epoch performance:  10.823sec Trl:0.211524 \tTrem:0.962222 \tTeem:0.084034\n",
      "\n",
      "Epoch:  27 / 300\n",
      "Batch:\t0 /9\t:  1.132489 1.132503 \tl:1.229771 \tem:0.840000\n",
      "Batch:\t1 /9\t:  1.150885 2.284243 \tl:0.388801 \tem:0.940000\n",
      "Batch:\t2 /9\t:  1.155574 3.440433 \tl:0.451413 \tem:0.900000\n",
      "Batch:\t3 /9\t:  1.150624 4.592184 \tl:0.621100 \tem:0.780000\n",
      "Batch:\t4 /9\t:  1.241045 5.834064 \tl:0.382346 \tem:0.900000\n",
      "Batch:\t5 /9\t:  1.260359 7.095088 \tl:0.447154 \tem:0.860000\n",
      "Batch:\t6 /9\t:  1.167361 8.263753 \tl:0.172787 \tem:0.960000\n",
      "Batch:\t7 /9\t:  1.223931 9.488414 \tl:0.187026 \tem:0.960000\n",
      "Batch:\t8 /9\t:  1.153172 10.64208 \tl:0.242688 \tem:0.940000\n",
      "\n",
      "Epoch performance:  10.906sec Trl:0.458121 \tTrem:0.897778 \tTeem:0.058824\n",
      "\n",
      "Epoch:  28 / 300\n",
      "Batch:\t0 /9\t:  1.518928 1.518967 \tl:0.483541 \tem:0.900000\n",
      "Batch:\t1 /9\t:  1.460944 2.981256 \tl:0.194580 \tem:0.980000\n",
      "Batch:\t2 /9\t:  1.264422 4.246182 \tl:0.217307 \tem:0.940000\n",
      "Batch:\t3 /9\t:  1.253206 5.499902 \tl:0.197237 \tem:0.960000\n",
      "Batch:\t4 /9\t:  1.250589 6.751192 \tl:0.657013 \tem:0.940000\n",
      "Batch:\t5 /9\t:  1.221285 7.972980 \tl:0.180138 \tem:0.940000\n",
      "Batch:\t6 /9\t:  1.277245 9.250890 \tl:0.274581 \tem:0.960000\n",
      "Batch:\t7 /9\t:  1.319735 10.57133 \tl:0.496165 \tem:0.860000\n",
      "Batch:\t8 /9\t:  1.147495 11.71935 \tl:0.487585 \tem:0.920000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch performance:  11.922sec Trl:0.354238 \tTrem:0.933333 \tTeem:0.075630\n",
      "\n",
      "Epoch:  29 / 300\n",
      "Batch:\t0 /9\t:  1.263029 1.263064 \tl:0.132502 \tem:0.980000\n",
      "Batch:\t1 /9\t:  1.134163 2.397529 \tl:0.216089 \tem:0.980000\n",
      "Batch:\t2 /9\t:  1.235943 3.633956 \tl:0.519170 \tem:0.860000\n",
      "Batch:\t3 /9\t:  1.140750 4.775264 \tl:0.081068 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.276683 6.053074 \tl:0.272484 \tem:0.940000\n",
      "Batch:\t5 /9\t:  1.255849 7.309520 \tl:0.391167 \tem:0.920000\n",
      "Batch:\t6 /9\t:  1.291572 8.601897 \tl:0.115323 \tem:0.960000\n",
      "Batch:\t7 /9\t:  1.231757 9.834340 \tl:0.127221 \tem:0.980000\n",
      "Batch:\t8 /9\t:  1.303370 11.13852 \tl:0.145128 \tem:0.960000\n",
      "\n",
      "Epoch performance:  11.333sec Trl:0.222239 \tTrem:0.953333 \tTeem:0.092437\n",
      "\n",
      "Epoch:  30 / 300\n",
      "Batch:\t0 /9\t:  1.116404 1.116422 \tl:0.239237 \tem:0.920000\n",
      "Batch:\t1 /9\t:  1.182496 2.301158 \tl:0.087611 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.160629 3.462733 \tl:0.508959 \tem:0.920000\n",
      "Batch:\t3 /9\t:  1.172952 4.636386 \tl:0.467708 \tem:0.920000\n",
      "Batch:\t4 /9\t:  1.217954 5.854579 \tl:0.061355 \tem:0.980000\n",
      "Batch:\t5 /9\t:  1.136584 6.991850 \tl:0.037447 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.265197 8.258074 \tl:0.115174 \tem:0.980000\n",
      "Batch:\t7 /9\t:  1.271561 9.530804 \tl:0.382442 \tem:0.940000\n",
      "Batch:\t8 /9\t:  1.193507 10.72493 \tl:0.165168 \tem:0.960000\n",
      "\n",
      "Epoch performance:  10.937sec Trl:0.229455 \tTrem:0.957778 \tTeem:0.075630\n",
      "\n",
      "Epoch:  31 / 300\n",
      "Batch:\t0 /9\t:  1.246806 1.246822 \tl:0.256373 \tem:0.960000\n",
      "Batch:\t1 /9\t:  1.239560 2.487160 \tl:0.158830 \tem:0.940000\n",
      "Batch:\t2 /9\t:  1.147406 3.635129 \tl:0.065396 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.237118 4.873504 \tl:0.068844 \tem:0.980000\n",
      "Batch:\t4 /9\t:  1.217201 6.091695 \tl:0.310289 \tem:0.960000\n",
      "Batch:\t5 /9\t:  1.160037 7.252893 \tl:0.097869 \tem:0.980000\n",
      "Batch:\t6 /9\t:  1.170094 8.423710 \tl:0.119137 \tem:0.960000\n",
      "Batch:\t7 /9\t:  1.145187 9.569894 \tl:0.112964 \tem:0.960000\n",
      "Batch:\t8 /9\t:  1.173043 10.74345 \tl:0.461903 \tem:0.960000\n",
      "\n",
      "Epoch performance:  10.961sec Trl:0.183512 \tTrem:0.966667 \tTeem:0.075630\n",
      "\n",
      "Epoch:  32 / 300\n",
      "Batch:\t0 /9\t:  1.304976 1.304994 \tl:0.128101 \tem:0.980000\n",
      "Batch:\t1 /9\t:  1.156800 2.462604 \tl:0.042034 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.156097 3.619190 \tl:0.229340 \tem:0.940000\n",
      "Batch:\t3 /9\t:  1.175184 4.795655 \tl:0.115160 \tem:0.980000\n",
      "Batch:\t4 /9\t:  1.250738 6.047827 \tl:0.101318 \tem:0.980000\n",
      "Batch:\t5 /9\t:  1.583126 7.631261 \tl:0.198439 \tem:0.960000\n",
      "Batch:\t6 /9\t:  1.401427 9.033230 \tl:0.075115 \tem:0.960000\n",
      "Batch:\t7 /9\t:  1.459371 10.49368 \tl:0.103723 \tem:0.960000\n",
      "Batch:\t8 /9\t:  1.540400 12.03516 \tl:0.064589 \tem:1.000000\n",
      "\n",
      "Epoch performance:  12.273sec Trl:0.117536 \tTrem:0.973333 \tTeem:0.075630\n",
      "\n",
      "Epoch:  33 / 300\n",
      "Batch:\t0 /9\t:  1.173272 1.173293 \tl:0.127260 \tem:0.980000\n",
      "Batch:\t1 /9\t:  1.238516 2.413104 \tl:0.106190 \tem:0.980000\n",
      "Batch:\t2 /9\t:  1.547795 3.961426 \tl:0.083263 \tem:0.960000\n",
      "Batch:\t3 /9\t:  1.449827 5.411539 \tl:0.061024 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.414638 6.827326 \tl:0.057452 \tem:0.980000\n",
      "Batch:\t5 /9\t:  1.241227 8.069089 \tl:0.026711 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.322561 9.391838 \tl:0.017450 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.303658 10.69577 \tl:0.020975 \tem:1.000000\n",
      "Batch:\t8 /9\t:  1.404665 12.10110 \tl:0.110804 \tem:0.960000\n",
      "\n",
      "Epoch performance:  12.288sec Trl:0.067903 \tTrem:0.984444 \tTeem:0.126050\n",
      "\n",
      "Epoch:  34 / 300\n",
      "Batch:\t0 /9\t:  1.126632 1.126652 \tl:0.011386 \tem:1.000000\n",
      "Batch:\t1 /9\t:  1.129492 2.256428 \tl:0.034169 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.249966 3.506677 \tl:0.030854 \tem:0.980000\n",
      "Batch:\t3 /9\t:  1.267781 4.774906 \tl:0.096535 \tem:0.940000\n",
      "Batch:\t4 /9\t:  1.061109 5.836410 \tl:0.013233 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.288004 7.124893 \tl:0.150178 \tem:0.940000\n",
      "Batch:\t6 /9\t:  1.244510 8.369922 \tl:0.012555 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.270628 9.640988 \tl:0.104622 \tem:0.960000\n",
      "Batch:\t8 /9\t:  1.380522 11.02244 \tl:0.047266 \tem:0.980000\n",
      "\n",
      "Epoch performance:  11.229sec Trl:0.055644 \tTrem:0.977778 \tTeem:0.117647\n",
      "\n",
      "Epoch:  35 / 300\n",
      "Batch:\t0 /9\t:  1.310647 1.310662 \tl:0.033183 \tem:1.000000\n",
      "Batch:\t1 /9\t:  1.094409 2.405524 \tl:0.080411 \tem:0.980000\n",
      "Batch:\t2 /9\t:  1.154347 3.560178 \tl:0.006662 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.154623 4.715358 \tl:0.039227 \tem:0.980000\n",
      "Batch:\t4 /9\t:  1.223133 5.939422 \tl:0.018775 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.077409 7.017361 \tl:0.017866 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.201864 8.219948 \tl:0.014453 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.307782 9.528367 \tl:0.017497 \tem:1.000000\n",
      "Batch:\t8 /9\t:  1.285730 10.81461 \tl:0.009960 \tem:1.000000\n",
      "\n",
      "Epoch performance:  11.025sec Trl:0.026448 \tTrem:0.995556 \tTeem:0.075630\n",
      "\n",
      "Epoch:  36 / 300\n",
      "Batch:\t0 /9\t:  1.306935 1.306950 \tl:0.184320 \tem:0.960000\n",
      "Batch:\t1 /9\t:  1.157548 2.465718 \tl:0.010502 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.210880 3.677656 \tl:0.019660 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.163422 4.841791 \tl:0.014353 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.601991 6.444325 \tl:0.009526 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.290225 7.735598 \tl:0.017889 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.233519 8.969784 \tl:0.005995 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.582619 10.55343 \tl:0.017900 \tem:1.000000\n",
      "Batch:\t8 /9\t:  1.522273 12.07706 \tl:0.280386 \tem:0.960000\n",
      "\n",
      "Epoch performance:  12.310sec Trl:0.062281 \tTrem:0.991111 \tTeem:0.092437\n",
      "\n",
      "Epoch:  37 / 300\n",
      "Batch:\t0 /9\t:  1.277458 1.277473 \tl:0.007286 \tem:1.000000\n",
      "Batch:\t1 /9\t:  1.154413 2.432528 \tl:0.007514 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.237256 3.670723 \tl:0.009934 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.064671 4.736176 \tl:0.018079 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.237916 5.974282 \tl:0.021428 \tem:0.980000\n",
      "Batch:\t5 /9\t:  1.144423 7.120061 \tl:0.008727 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.314806 8.435919 \tl:0.007815 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.235635 9.672281 \tl:0.006758 \tem:1.000000\n",
      "Batch:\t8 /9\t:  1.172813 10.84586 \tl:0.011136 \tem:1.000000\n",
      "\n",
      "Epoch performance:  11.130sec Trl:0.010964 \tTrem:0.997778 \tTeem:0.100840\n",
      "\n",
      "Epoch:  38 / 300\n",
      "Batch:\t0 /9\t:  1.535665 1.535705 \tl:0.005180 \tem:1.000000\n",
      "Batch:\t1 /9\t:  1.373528 2.910514 \tl:0.007341 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.066848 3.977653 \tl:0.006356 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.247753 5.226138 \tl:0.005672 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.284780 6.511795 \tl:0.004219 \tem:1.000000\n",
      "Batch:\t5 /9\t:  1.326972 7.839516 \tl:0.012529 \tem:1.000000\n",
      "Batch:\t6 /9\t:  1.161681 9.001480 \tl:0.005070 \tem:1.000000\n",
      "Batch:\t7 /9\t:  1.202560 10.20432 \tl:0.004213 \tem:1.000000\n",
      "Batch:\t8 /9\t:  1.145364 11.35044 \tl:0.005638 \tem:1.000000\n",
      "Saving new model on epoch 38\n",
      "\n",
      "Epoch performance:  12.287sec Trl:0.006247 \tTrem:1.000000 \tTeem:0.100840\n",
      "\n",
      "Epoch:  39 / 300\n",
      "Batch:\t0 /9\t:  1.383306 1.383326 \tl:0.005954 \tem:1.000000\n",
      "Batch:\t1 /9\t:  1.166561 2.550380 \tl:0.004197 \tem:1.000000\n",
      "Batch:\t2 /9\t:  1.138293 3.689965 \tl:0.006917 \tem:1.000000\n",
      "Batch:\t3 /9\t:  1.309993 5.000536 \tl:0.004079 \tem:1.000000\n",
      "Batch:\t4 /9\t:  1.157848 6.159118 \tl:0.003964 \tem:1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-9-f205e19f0955>\", line 100, in train\n",
      "    loss.backward()\n",
      "  File \"/data/priyansh/virtualenvironment/pwc-reg-m/local/lib/python2.7/site-packages/torch/tensor.py\", line 93, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/data/priyansh/virtualenvironment/pwc-reg-m/local/lib/python2.7/site-packages/torch/autograd/__init__.py\", line 89, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-12-48eec81c8ecd>\", line 89, in training_loop\n",
      "    debug=_macros['debug']\n",
      "TypeError: 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "op = training_loop(_models=[ques_model, para_model, mlstm_model, pointer_decoder_model],\n",
    "                   _data=data,\n",
    "                   _debug=macros['debug'],\n",
    "                   _save=-1,\n",
    "                   _test_eval=1,\n",
    "                   _train_eval=1,\n",
    "                   _epochs=EPOCHS,\n",
    "                   _macros=macros)    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# See if gradients are being passed\n",
    "p = list(filter(lambda p: p.requires_grad, ques_model.parameters())) + \\\n",
    "    list(filter(lambda p: p.requires_grad, para_model.parameters())) + \\\n",
    "    list(para_model.parameters()) + \\\n",
    "    list(pointer_decoder_model.parameters())\n",
    "                       \n",
    "print([ x.grad.sum().item() for x in p])                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations\n",
    "\n",
    "So far, we plot the training losss. \n",
    "Shall we superimpose test loss on it too? We don't calculate test loss per batch though (fortunately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training EM\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing EM\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizations\n",
    "print(\"Training Loss\")\n",
    "visualize_loss(op[0], \"train loss\", _only_epoch=True)\n",
    "\n",
    "# if len(op[1]) > 0:\n",
    "\n",
    "print(\"Training EM\")\n",
    "visualize_loss(op[1], \"train em\", _only_epoch=True)\n",
    "\n",
    "print(\"Testing EM\")\n",
    "visualize_loss(op[3], \"test em\")\n",
    "\n",
    "\n",
    "# print(op[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing (temp)\n",
    "# models = { 'ques_model': ques_model,\n",
    "#            'para_model': para_model,\n",
    "#            'mlstm_model':  mlstm_model,\n",
    "#            'pointer_decoder_model': pointer_decoder_model\n",
    "#          }\n",
    "# save_model(loc=macros['save_model_loc'], models=models, epochs=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,\n",
      "         44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,\n",
      "         44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,\n",
      "         44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,\n",
      "         44,  44], device='cuda:0')\n",
      "tensor([ 44,  44,  44,  44,  44,  44,  44,  44,  44,  44], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# # Try loading the model\n",
    "# ques_model = torch.load(os.path.join(macros['save_model_loc'], 'ques_model.torch'))\n",
    "# print(\"Ques Model\\n\", ques_model)\n",
    "\n",
    "# para_model = torch.load(os.path.join(macros['save_model_loc'], 'para_model.torch'))\n",
    "# print(\"Para Model\\n\", para_model)\n",
    "\n",
    "# mlstm_model = torch.load(os.path.join(macros['save_model_loc'], 'mlstm_model.torch'))\n",
    "# print(\"MLSTM Model\\n\", mlstm_model)\n",
    "\n",
    "# pointer_decoder_model = torch.load(os.path.join(macros['save_model_loc'], 'pointer_decoder_model.torch'))\n",
    "# print(\"Pointer Decoder model\\n\", pointer_decoder_model)\n",
    "\n",
    "# Create dummy data for testing the predict fn\n",
    "q = np.random.randint(0, len(vectors), (1, 30))\n",
    "p = np.random.randint(0, len(vectors), (1, 200))\n",
    "qa = np.repeat(q,macros['batch_size'],axis=0)\n",
    "pa = np.repeat(p,macros['batch_size'],axis=0)\n",
    "\n",
    "qb = np.repeat(q,10,axis=0)\n",
    "pb = np.repeat(p,10,axis=0)\n",
    "\n",
    "# print(p_repeat.shape)\n",
    "# print(q_repeat.shape)\n",
    "\n",
    "ysa, yea, _ = predict(torch.tensor(pa, dtype=torch.long, device=device), \n",
    "                                   torch.tensor(qa, dtype=torch.long, device=device),\n",
    "                                   ques_model=ques_model.eval(),\n",
    "                                   para_model=para_model.eval(),\n",
    "                                   mlstm_model=mlstm_model.eval(),\n",
    "                                   pointer_decoder_model=pointer_decoder_model.eval(),\n",
    "                                    macros=macros,\n",
    "                                    debug=macros['debug'])\n",
    "\n",
    "ysb, yeb, _ = predict(torch.tensor(pb, dtype=torch.long, device=device), \n",
    "                                   torch.tensor(qb, dtype=torch.long, device=device),\n",
    "                                   ques_model=ques_model.eval(),\n",
    "                                   para_model=para_model.eval(),\n",
    "                                   mlstm_model=mlstm_model.eval(),\n",
    "                                   pointer_decoder_model=pointer_decoder_model.eval(),\n",
    "                                    macros=macros,\n",
    "                                    debug=macros['debug'])\n",
    "\n",
    "print(torch.argmax(ysa.squeeze(), dim=1))\n",
    "print(torch.argmax(ysb.squeeze(), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_cap_start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fa5a9cdceeff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cap_start\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_cap_start' is not defined"
     ]
    }
   ],
   "source": [
    "torch.argmax(y_cap_start.squeeze(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
